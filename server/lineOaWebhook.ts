import { Request, Response } from "express";
import OpenAI from "openai";
import { storage } from "./storage";
import { db } from "./db";
import { sql } from "drizzle-orm";
import crypto from "crypto";
import { LineImageService } from "./lineImageService";
import { GuardrailsService, GuardrailConfig } from "./services/guardrails";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface LineMessage {
  type: string;
  id: string;
  text?: string;
  // Image message
  contentProvider?: {
    type: string;
  };
  // Sticker message
  packageId?: string;
  stickerId?: string;
}

interface LineEvent {
  type: string;
  message?: LineMessage;
  replyToken?: string;
  source: {
    userId: string;
    type: string;
  };
}

interface LineWebhookBody {
  destination: string;
  events: LineEvent[];
}

// Verify Line signature
function verifyLineSignature(
  body: string,
  signature: string,
  channelSecret: string,
): boolean {
  const hash = crypto
    .createHmac("sha256", channelSecret)
    .update(body)
    .digest("base64");

  return hash === signature;
}

// Send reply message to Line
async function sendLineReply(
  replyToken: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        replyToken,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      console.error("‚ùå Line API Error:", await response.text());
      return false;
    }

    console.log("‚úÖ Line reply sent successfully");
    return true;
  } catch (error) {
    console.error("üí• Error sending Line reply:", error);
    return false;
  }
}

// Send push message to Line user (for Human Agent messages)
export async function sendLinePushMessage(
  userId: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/push", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        to: userId,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Line Push API Error:", errorText);
      return false;
    }

    console.log("‚úÖ Line push message sent successfully to:", userId);
    return true;
  } catch (error) {
    console.error("üí• Error sending Line push message:", error);
    return false;
  }
}

// Send image message to Line user (for Human Agent images)
export async function sendLineImageMessage(
  userId: string,
  imageUrl: string,
  channelAccessToken: string,
  captionText?: string,
) {
  try {
    // Convert relative URL to absolute URL for Line API
    const protocol = "https:";
    const host = process.env.REPLIT_DOMAINS || "localhost:5000";
    const absoluteImageUrl = `${protocol}//${host}${imageUrl}`;

    console.log("üì∏ Sending Line image message:", {
      userId,
      absoluteImageUrl,
      captionText,
    });

    const messages: any[] = [
      {
        type: "image",
        originalContentUrl: absoluteImageUrl,
        previewImageUrl: absoluteImageUrl,
      },
    ];

    // Add caption text as separate message if provided
    if (captionText && captionText.trim()) {
      messages.push({
        type: "text",
        text: captionText,
      });
    }

    const response = await fetch("https://api.line.me/v2/bot/message/push", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        to: userId,
        messages: messages,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Line Push Image API Error:", errorText);
      return false;
    }

    console.log("‚úÖ Line image message sent successfully to:", userId);
    return true;
  } catch (error) {
    console.error("üí• Error sending Line image message:", error);
    return false;
  }
}

// Get AI response using OpenAI with chat history
/**
 * Detect if user message is asking about image content
 */
function isImageRelatedQuery(message: string): boolean {
  const imageKeywords = [
    "‡∏£‡∏π‡∏õ",
    "‡∏£‡∏π‡∏õ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö",
    "‡∏†‡∏≤‡∏û",
    "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û",
    "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢",
    "image",
    "picture",
    "photo",
    "‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏∞‡πÑ‡∏£",
    "‡πÉ‡∏ô‡∏£‡∏π‡∏õ",
    "‡πÉ‡∏ô‡∏†‡∏≤‡∏û",
    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
    "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢",
    "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô",
    "‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ",
    "‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö",
    "what's in",
    "describe",
    "tell me about",
    "show",
    "picture",
    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
    "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î",
    "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
    "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô",
  ];

  const lowerMessage = message.toLowerCase();
  return imageKeywords.some((keyword) =>
    lowerMessage.includes(keyword.toLowerCase()),
  );
}

/**
 * Extract image analysis from system messages
 */
function extractImageAnalysis(messages: any[]): string {
  const systemMessages = messages.filter(
    (msg) =>
      msg.messageType === "system" &&
      msg.metadata?.messageType === "image_analysis",
  );

  if (systemMessages.length === 0) {
    return "";
  }

  let imageContext = "\n=== ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ===\n";

  // Get the most recent image analyses (last 3)
  const recentAnalyses = systemMessages.slice(-3);

  recentAnalyses.forEach((msg, index) => {
    const analysisContent = msg.content.replace("[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ", "");
    imageContext += `\n--- ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà ${index + 1} ---\n${analysisContent}\n`;
  });

  return imageContext;
}

// New function to get AI response without saving chat history (to prevent duplicates)
async function getAiResponseDirectly(
  userMessage: string,
  agentId: number,
  userId: string,
  channelType: string,
  channelId: string,
): Promise<string> {
  try {
    console.log(`üîç Debug: Getting agent ${agentId} for user ${userId}`);

    // Get agent configuration
    const agent = await storage.getAgentChatbot(agentId, userId);
    if (!agent) {
      console.log(`‚ùå Agent ${agentId} not found for user ${userId}`);
      return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";
    }

    console.log(`‚úÖ Found agent: ${agent.name}`);

    // Check if this is an image-related query
    const isImageRelatedQuery = (message: string): boolean => {
      const imageKeywords = [
        "‡∏£‡∏π‡∏õ",
        "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û",
        "‡∏†‡∏≤‡∏û",
        "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢",
        "‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏£‡∏π‡∏õ",
        "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤",
        "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î",
        "image",
        "picture",
        "photo",
      ];

      const lowerMessage = message.toLowerCase();
      return imageKeywords.some((keyword) => lowerMessage.includes(keyword));
    };
    const isImageQuery = isImageRelatedQuery(userMessage);
    console.log(`üñºÔ∏è Image-related query detected: ${isImageQuery}`);
    console.log(`üîç User message for analysis: "${userMessage}"`);

    // Get chat history if memory is enabled
    let chatHistory: any[] = [];
    if (agent.memoryEnabled) {
      const memoryLimit = agent.memoryLimit || 10;
      console.log(
        `üìö Fetching chat history (limit: ${memoryLimit}) for channel type: ${channelType}`,
      );

      try {
        if (channelType === "chat_widget") {
          // For widget chat, fetch from widgetChatMessages table
          const { widgetChatMessages } = await import("@shared/schema");
          const { db } = await import("./db");
          const { desc, eq } = await import("drizzle-orm");

          const widgetMessages = await db
            .select({
              role: widgetChatMessages.role,
              content: widgetChatMessages.content,
              messageType: widgetChatMessages.messageType,
              metadata: widgetChatMessages.metadata,
              createdAt: widgetChatMessages.createdAt,
            })
            .from(widgetChatMessages)
            .where(eq(widgetChatMessages.sessionId, channelId))
            .orderBy(desc(widgetChatMessages.createdAt))
            .limit(memoryLimit);

          // Convert widget messages to chat history format
          chatHistory = widgetMessages.reverse().map((msg) => ({
            messageType: msg.role,
            content: msg.content,
            metadata: msg.metadata,
            createdAt: msg.createdAt,
          }));

          console.log(`üìù Found ${chatHistory.length} widget chat messages`);
        } else {
          // Use regular chat history for Line OA and other channels
          chatHistory = await storage.getChatHistoryWithMemoryStrategy(
            userId,
            channelType,
            channelId,
            agentId,
            memoryLimit,
          );
          console.log(
            `üìù Found ${chatHistory.length} previous messages (all types included)`,
          );
        }
      } catch (error) {
        console.error("‚ö†Ô∏è Error fetching chat history:", error);
        if (channelType !== "chat_widget") {
          // Fallback to original method for non-widget channels
          try {
            chatHistory = await storage.getChatHistory(
              userId,
              channelType,
              channelId,
              agentId,
              memoryLimit,
            );
            console.log(
              `üìù Fallback: Found ${chatHistory.length} previous messages`,
            );
          } catch (fallbackError) {
            console.error("‚ö†Ô∏è Fallback error:", fallbackError);
          }
        }
      }
    }

    // Get agent's documents for context using vector search
    const agentDocs = await storage.getAgentChatbotDocuments(agentId, userId);
    let contextPrompt = "";

    // Initialize documentContents in the correct scope
    const documentContents: string[] = [];

    if (agentDocs.length > 0) {
      console.log(`üìö Found ${agentDocs.length} documents for agent`);

      // Use unified search service for consistent behavior across all platforms
      try {
        const { unifiedSearchService } = await import(
          "./services/unifiedSearchService"
        );

        // Search for relevant chunks ONLY from agent's documents using unified search
        const agentDocIds = agentDocs.map((d) => d.documentId);
        console.log(
          `LINE OA: Using unified search with agent's ${agentDocIds.length} documents: [${agentDocIds.join(", ")}]`,
        );

        const hybridResults = await unifiedSearchService.searchAgentDocuments(
          userMessage,
          userId,
          agentDocIds,
          {
            searchType: "hybrid",
            limit: 2, // Only get top 2 chunks globally as requested
            keywordWeight: 0.4,
            vectorWeight: 0.6,
          },
        );

        console.log(
          `üîç Line OA: Found ${hybridResults.length} relevant chunks using hybrid search`,
        );

        if (hybridResults.length > 0) {
          // Use only the content from the top 2 chunks
          hybridResults.forEach((result, index) => {
            documentContents.push(
              `=== ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ${result.name} (Chunk ${index + 1}) ===\n${result.content}\n`,
            );
          });

          console.log(
            `üìÑ Line OA: Using hybrid search with ${hybridResults.length} top chunks globally (Total chars: ${documentContents.join("").length})`,
          );
        } else {
          console.log(
            `üìÑ Line OA: No relevant chunks found, using fallback approach`,
          );
          // Fallback to original approach with first few documents
          for (const agentDoc of agentDocs.slice(0, 3)) {
            try {
              const document = await storage.getDocument(
                agentDoc.documentId,
                userId,
              );
              if (document && document.content) {
                const contentPreview =
                  document.content.substring(0, 3000) +
                  (document.content.length > 3000 ? "..." : "");
                documentContents.push(
                  `=== ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ${document.name} ===\n${contentPreview}\n`,
                );
              }
            } catch (error) {
              console.error(
                `‚ùå Error fetching document ${agentDoc.documentId}:`,
                error,
              );
            }
          }
        }
      } catch (vectorError) {
        console.error(
          `‚ùå Line OA: Vector search failed, using fallback:`,
          vectorError,
        );
        // Fallback to original approach with limited documents
        for (const agentDoc of agentDocs.slice(0, 3)) {
          try {
            const document = await storage.getDocument(
              agentDoc.documentId,
              userId,
            );
            if (document && document.content) {
              const contentPreview =
                document.content.substring(0, 3000) +
                (document.content.length > 3000 ? "..." : "");
              documentContents.push(
                `=== ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ${document.name} ===\n${contentPreview}\n`,
              );
            }
          } catch (error) {
            console.error(
              `‚ùå Error fetching document ${agentDoc.documentId}:`,
              error,
            );
          }
        }
      }

      if (documentContents.length > 0) {
        contextPrompt = `\n\n‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n${documentContents.join("\n")}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢`;
        console.log(
          `‚úÖ Built context with ${documentContents.length} documents`,
        );
        console.log(
          `üìÑ Context prompt length: ${contextPrompt.length} characters`,
        );
      } else {
        console.log(`‚ö†Ô∏è No documents found or no content available`);
      }
    }

    // Always extract image analysis from recent chat history to maintain context
    let imageContext = "";
    if (chatHistory.length > 0) {
      imageContext = extractImageAnalysis(chatHistory);
      console.log(
        `üì∏ Image context extracted: ${imageContext.length} characters`,
      );
      if (imageContext) {
        console.log(
          `‚úÖ Image analysis found: ${imageContext.substring(0, 200)}...`,
        );

        // Debug: Show all system messages for analysis
        const systemMessages = chatHistory.filter(
          (msg) =>
            msg.messageType === "system" &&
            msg.metadata?.messageType === "image_analysis",
        );
        console.log(
          `üîç Found ${systemMessages.length} image analysis messages in chat history`,
        );
        systemMessages.forEach((msg, index) => {
          console.log(
            `üìã Analysis ${index + 1}: ${msg.content.substring(0, 150)}... (ID: ${msg.metadata?.relatedImageMessageId})`,
          );
        });
      } else {
        console.log(`‚ÑπÔ∏è No recent image analysis found in chat history`);

        // Debug: Show what system messages we have
        const allSystemMessages = chatHistory.filter(
          (msg) => msg.messageType === "system",
        );
        console.log(
          `üîç Total system messages in history: ${allSystemMessages.length}`,
        );
        allSystemMessages.forEach((msg, index) => {
          console.log(
            `üìù System ${index + 1}: ${msg.content.substring(0, 100)}... (metadata: ${JSON.stringify(msg.metadata)})`,
          );
        });
      }
    }

    // Build conversation messages including history
    const messages: any[] = [
      {
        role: "system",
        content: `${agent.systemPrompt}${contextPrompt}

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏≠‡∏¢‡πà‡∏≤‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ" ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô
‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°`,
      },
    ];

    // Add chat history (exclude system messages from conversation flow)
    const userBotMessages = chatHistory.filter(
      (msg) => msg.messageType === "user" || msg.messageType === "assistant",
    );

    userBotMessages.forEach((msg) => {
      messages.push({
        role: msg.messageType === "user" ? "user" : "assistant",
        content: msg.content,
      });
    });

    // Add current user message with image context attached if available
    let enhancedUserMessage = userMessage;
    if (imageContext) {
      enhancedUserMessage = `${userMessage}

${imageContext}`;
      console.log(
        `üñºÔ∏è Enhanced user message with image context (${imageContext.length} chars)`,
      );
    }

    messages.push({
      role: "user",
      content: enhancedUserMessage,
    });

    console.log(
      `ü§ñ Sending ${messages.length} messages to OpenAI (including ${chatHistory.length} history messages)`,
    );

    // Initialize guardrails service if configured
    let guardrailsService: GuardrailsService | null = null;
    if (agent.guardrailsConfig) {
      guardrailsService = new GuardrailsService(agent.guardrailsConfig);
      console.log(`üõ°Ô∏è === GUARDRAILS SYSTEM ENABLED ===`);
      console.log(`üõ°Ô∏è Agent ID: ${agentId}, Agent Name: ${agent.name}`);
      console.log(
        `üõ°Ô∏è Guardrails Configuration:`,
        JSON.stringify(agent.guardrailsConfig, null, 2),
      );

      // Show which guardrails features are enabled/disabled
      const features = [];
      if (agent.guardrailsConfig.contentFiltering?.enabled) {
        const contentSettings = [];
        if (agent.guardrailsConfig.contentFiltering.blockProfanity)
          contentSettings.push("Profanity");
        if (agent.guardrailsConfig.contentFiltering.blockHateSpeech)
          contentSettings.push("Hate Speech");
        if (agent.guardrailsConfig.contentFiltering.blockSexualContent)
          contentSettings.push("Sexual Content");
        if (agent.guardrailsConfig.contentFiltering.blockViolence)
          contentSettings.push("Violence");
        features.push(`Content Filtering: ${contentSettings.join(", ")}`);
      }
      if (agent.guardrailsConfig.privacyProtection?.enabled) {
        const privacySettings = [];
        if (agent.guardrailsConfig.privacyProtection.blockPersonalInfo)
          privacySettings.push("Personal Info");
        if (agent.guardrailsConfig.privacyProtection.blockFinancialInfo)
          privacySettings.push("Financial Info");
        if (agent.guardrailsConfig.privacyProtection.blockHealthInfo)
          privacySettings.push("Health Info");
        if (agent.guardrailsConfig.privacyProtection.maskPhoneNumbers)
          privacySettings.push("Phone Masking");
        if (agent.guardrailsConfig.privacyProtection.maskEmails)
          privacySettings.push("Email Masking");
        features.push(`Privacy Protection: ${privacySettings.join(", ")}`);
      }
      if (agent.guardrailsConfig.toxicityPrevention?.enabled) {
        features.push(
          `Toxicity Prevention: Threshold ${agent.guardrailsConfig.toxicityPrevention.toxicityThreshold}`,
        );
      }
      if (agent.guardrailsConfig.responseQuality?.enabled) {
        features.push(
          `Response Quality: ${agent.guardrailsConfig.responseQuality.minResponseLength}-${agent.guardrailsConfig.responseQuality.maxResponseLength} chars`,
        );
      }
      if (agent.guardrailsConfig.topicControl?.enabled) {
        features.push(
          `Topic Control: ${agent.guardrailsConfig.topicControl.strictMode ? "Strict" : "Lenient"} mode`,
        );
      }
      if (agent.guardrailsConfig.businessContext?.enabled) {
        features.push(`Business Context: Professional tone required`);
      }

      console.log(`üõ°Ô∏è Active Features: ${features.join(" | ")}`);
      console.log(`üõ°Ô∏è === END GUARDRAILS INITIALIZATION ===`);
    } else {
      console.log(`üõ°Ô∏è Guardrails: DISABLED (no configuration found)`);
    }

    // Validate user input with guardrails
    if (guardrailsService) {
      console.log(`üîç === STARTING INPUT VALIDATION ===`);
      console.log(`üìù Original User Message: "${enhancedUserMessage}"`);

      const inputValidation = await guardrailsService.evaluateInput(
        enhancedUserMessage,
        {
          documents: documentContents,
          agent: agent,
        },
      );

      console.log(`üìä Input Validation Summary:`);
      console.log(`   ‚úì Allowed: ${inputValidation.allowed}`);
      console.log(`   ‚úì Confidence: ${inputValidation.confidence}`);
      console.log(
        `   ‚úì Triggered Rules: ${inputValidation.triggeredRules.join(", ") || "None"}`,
      );
      console.log(
        `   ‚úì Reason: ${inputValidation.reason || "No issues found"}`,
      );

      if (!inputValidation.allowed) {
        console.log(`üö´ === INPUT BLOCKED BY GUARDRAILS ===`);
        console.log(`üö´ Blocking Reason: ${inputValidation.reason}`);
        console.log(
          `üö´ Triggered Rules: ${inputValidation.triggeredRules.join(", ")}`,
        );
        const suggestions = inputValidation.suggestions?.join(" ") || "";
        const blockedMessage = `‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ ${inputValidation.reason ? `(${inputValidation.reason})` : ""} ${suggestions}`;
        console.log(`üö´ Returning blocked message: "${blockedMessage}"`);
        return blockedMessage;
      }

      // Use modified content if privacy protection applied masking
      if (inputValidation.modifiedContent) {
        console.log(`üîí User input modified for privacy protection`);
        console.log(`üîí Original: "${enhancedUserMessage}"`);
        console.log(`üîí Modified: "${inputValidation.modifiedContent}"`);
        enhancedUserMessage = inputValidation.modifiedContent;
      }

      console.log(`‚úÖ INPUT VALIDATION PASSED - Proceeding to OpenAI`);
    } else {
      console.log(`‚è≠Ô∏è Skipping input validation - Guardrails disabled`);
    }

    // Debug: Log the complete system prompt for verification
    console.log("\n=== üîç DEBUG: Complete System Prompt ===");
    console.log(messages[0].content);
    console.log("=== End System Prompt ===\n");

    // Debug: Log user message
    console.log(`üìù User Message: "${userMessage}"`);

    // Debug: Log total prompt length
    const totalTokens = messages.reduce(
      (sum, msg) => sum + msg.content.length,
      0,
    );
    console.log(`üìä Total prompt length: ${totalTokens} characters`);

    const response = await openai.chat.completions.create({
      model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
      messages: messages,
      max_tokens: 1000,
      temperature: 0.7,
    });

    let aiResponse =
      response.choices[0].message.content ||
      "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";

    // Validate AI output with guardrails
    if (guardrailsService) {
      console.log(`üîç === STARTING OUTPUT VALIDATION ===`);
      console.log(`ü§ñ Original AI Response: "${aiResponse}"`);

      const outputValidation = await guardrailsService.evaluateOutput(
        aiResponse,
        {
          documents: documentContents,
          agent: agent,
          userQuery: userMessage,
        },
      );

      console.log(`üìä Output Validation Summary:`);
      console.log(`   ‚úì Allowed: ${outputValidation.allowed}`);
      console.log(`   ‚úì Confidence: ${outputValidation.confidence}`);
      console.log(
        `   ‚úì Triggered Rules: ${outputValidation.triggeredRules.join(", ") || "None"}`,
      );
      console.log(
        `   ‚úì Reason: ${outputValidation.reason || "No issues found"}`,
      );

      if (!outputValidation.allowed) {
        console.log(`üö´ === OUTPUT BLOCKED BY GUARDRAILS ===`);
        console.log(`üö´ Blocking Reason: ${outputValidation.reason}`);
        console.log(
          `üö´ Triggered Rules: ${outputValidation.triggeredRules.join(", ")}`,
        );
        const suggestions = outputValidation.suggestions?.join(" ") || "";
        const blockedMessage = `‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ ${outputValidation.reason ? `(${outputValidation.reason})` : ""} ${suggestions}`;
        console.log(`üö´ Original blocked response: "${aiResponse}"`);
        console.log(`üö´ Returning blocked message: "${blockedMessage}"`);
        aiResponse = blockedMessage;
      } else if (outputValidation.modifiedContent) {
        console.log(`üîí AI output modified for compliance`);
        console.log(`üîí Original: "${aiResponse}"`);
        console.log(`üîí Modified: "${outputValidation.modifiedContent}"`);
        aiResponse = outputValidation.modifiedContent;
      }

      console.log(`‚úÖ OUTPUT VALIDATION PASSED - Final response ready`);
      console.log(`üìù Final AI Response: "${aiResponse}"`);
    } else {
      console.log(`‚è≠Ô∏è Skipping output validation - Guardrails disabled`);
    }

    // NOTE: Chat history saving is now handled by the calling function to prevent duplicates
    console.log(
      `ü§ñ Generated AI response for user ${userId} (${aiResponse.length} characters)`,
    );

    return aiResponse;
  } catch (error) {
    console.error("üí• Error getting AI response:", error);
    return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á";
  }
}

// Store processed message IDs to prevent duplicates with timestamp for cleanup
const processedMessageIds = new Map<string, number>();

// Clean up old processed message IDs (older than 1 hour)
const cleanupProcessedMessages = () => {
  const oneHourAgo = Date.now() - 60 * 60 * 1000;
  for (const [messageId, timestamp] of processedMessageIds.entries()) {
    if (timestamp < oneHourAgo) {
      processedMessageIds.delete(messageId);
    }
  }
};

// Schedule cleanup every 30 minutes
setInterval(cleanupProcessedMessages, 30 * 60 * 1000);

// Main webhook handler
export async function handleLineWebhook(req: Request, res: Response) {
  try {
    const signature = req.headers["x-line-signature"] as string;
    const webhookBody: LineWebhookBody = req.body;
    const body = JSON.stringify(webhookBody);

    console.log("üîî Line webhook received");
    console.log("üìù Body:", body);

    let lineIntegration: any;

    // Check if integration is provided by dynamic webhook endpoint
    if ((req as any).lineIntegration) {
      lineIntegration = (req as any).lineIntegration;
      console.log(
        `‚úÖ Using provided integration: ${lineIntegration.name} (ID: ${lineIntegration.id})`,
      );
    } else {
      // Legacy webhook handling - find integration by destination
      const destination = webhookBody.destination;
      console.log(
        "üîç Debug: Looking for integration with destination:",
        destination,
      );

      // Get all Line OA integrations to find the matching one
      const allIntegrations = await storage.getAllSocialIntegrations();
      console.log(
        "‚úÖ Found",
        allIntegrations.length,
        "total social integrations",
      );

      // In Line webhooks, the destination is the Bot's User ID, not Channel ID
      // First try to match by Bot User ID, then fall back to any active integration
      lineIntegration = allIntegrations.find(
        (integration) =>
          integration.type === "lineoa" &&
          integration.isActive &&
          integration.botUserId === destination,
      );

      // If no exact match found by Bot User ID, try fallback to any active Line OA integration
      if (!lineIntegration) {
        lineIntegration = allIntegrations.find(
          (integration) =>
            integration.type === "lineoa" && integration.isActive,
        );
        if (lineIntegration) {
          console.log(
            "üîß Using fallback matching - found active Line OA integration",
          );
          // Update the Bot User ID for future webhook calls using raw SQL
          try {
            await db.execute(sql`
              UPDATE social_integrations 
              SET bot_user_id = ${destination}, updated_at = NOW() 
              WHERE id = ${lineIntegration.id}
            `);
            console.log("‚úÖ Updated Bot User ID for future webhook calls");
          } catch (error) {
            console.log("‚ö†Ô∏è Could not update Bot User ID:", error);
          }
        }
      }

      if (!lineIntegration) {
        console.log(
          "‚ùå No active Line OA integration found for destination:",
          destination,
        );
        return res
          .status(404)
          .json({ error: "No active Line OA integration found" });
      }
    }

    console.log(
      "‚úÖ Found matching Line OA integration for user:",
      lineIntegration.userId,
    );
    console.log(
      "üîë Debug: Channel Access Token available:",
      !!lineIntegration.channelAccessToken,
    );
    console.log(
      "üîç Debug: Integration object keys:",
      Object.keys(lineIntegration),
    );

    // Verify signature with debug logging
    console.log("üîê Debug: Signature verification details:");
    console.log("üìù Raw body length:", body.length);
    console.log(
      "üîë Channel Secret available:",
      !!lineIntegration.channelSecret,
    );
    console.log(
      "üîè Channel Secret length:",
      lineIntegration.channelSecret?.length || 0,
    );
    console.log("üìã X-Line-Signature header:", signature);
    console.log("üîó Integration ID:", lineIntegration.id);
    console.log("üè∑Ô∏è Integration name:", lineIntegration.name);

    // Generate expected hash for comparison
    const expectedHash = crypto
      .createHmac("sha256", lineIntegration.channelSecret!)
      .update(body)
      .digest("base64");
    console.log("üéØ Expected hash:", expectedHash);
    console.log("üì© Received signature:", signature);
    console.log("‚úÖ Hash match:", expectedHash === signature);

    if (!verifyLineSignature(body, signature, lineIntegration.channelSecret!)) {
      console.log("‚ùå Invalid Line signature");
      console.log("üîç Debug: Possible issues:");
      console.log(
        "  - Channel Secret mismatch between Line Developer Console and database",
      );
      console.log("  - Webhook URL configured for wrong integration");
      console.log("  - Request body modified by middleware");
      return res.status(401).json({ error: "Invalid signature" });
    }

    // Process each event
    for (const event of webhookBody.events) {
      if (event.type === "message" && event.message) {
        const message = event.message;
        const replyToken = event.replyToken!;
        let userMessage = "";
        let messageMetadata: any = {};

        console.log("üì± Message type:", message.type);
        console.log("üë§ User ID:", event.source.userId);

        // Handle different message types
        if (message.type === "text") {
          userMessage = message.text!;
          console.log("üí¨ Text message:", userMessage);
        } else if (message.type === "image") {
          userMessage = "[‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û]";

          // For Line images, construct content URLs using messageId and Channel Access Token
          const originalContentUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content`;
          const previewImageUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content/preview`;

          messageMetadata = {
            messageType: "image",
            messageId: message.id,
            contentProvider: message.contentProvider,
            originalContentUrl,
            previewImageUrl,
          };
          console.log("üñºÔ∏è Image message received, ID:", message.id);
          console.log("üîó Image URLs:", {
            originalContentUrl,
            previewImageUrl,
          });
        } else if (message.type === "sticker") {
          userMessage = "[‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå]";
          messageMetadata = {
            messageType: message.packageId,
            packageId: message.packageId,
            stickerId: message.stickerId,
          };
          console.log(
            "üòÄ Sticker message received, Package:",
            message.packageId,
            "Sticker:",
            message.stickerId,
          );
        } else {
          // Handle other message types (video, audio, location, etc.)
          userMessage = `[${message.type}]`;
          messageMetadata = {
            messageType: message.type,
            messageId: message.id,
          };
          console.log("üìé Other message type:", message.type);
        }

        // Check if this message has already been processed
        const messageId = message.id;
        if (processedMessageIds.has(messageId)) {
          console.log(`‚ö†Ô∏è Message ${messageId} already processed, skipping...`);
          continue;
        }

        // Mark message as processed with timestamp
        processedMessageIds.set(messageId, Date.now());
        console.log(`‚úÖ Processing new message ${messageId}`);

        // Save user message with metadata
        let chatHistoryId: number | null = null;
        try {
          const savedChatHistory = await storage.createChatHistory({
            userId: lineIntegration.userId,
            channelType: "lineoa",
            channelId: event.source.userId,
            agentId: lineIntegration.agentId!,
            messageType: "user",
            content: userMessage,
            metadata: messageMetadata,
          });
          chatHistoryId = savedChatHistory.id;
          console.log(
            "üíæ Saved user message with metadata, ID:",
            chatHistoryId,
          );
        } catch (error) {
          console.error("‚ö†Ô∏è Error saving user message:", error);
        }

        // Handle image messages with immediate acknowledgment
        if (message.type === "image" && lineIntegration.channelAccessToken) {
          console.log(
            "üñºÔ∏è Image message detected - sending immediate acknowledgment",
          );

          // 1. Send immediate acknowledgment
          await sendLineReply(
            replyToken,
            "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß ‡∏Ç‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ô‡∏∞‡∏Ñ‡∏∞",
            lineIntegration.channelAccessToken,
          );

          // 2. Process image and get analysis
          if (chatHistoryId && lineIntegration.agentId) {
            console.log("üñºÔ∏è Starting image processing...");
            const imageService = LineImageService.getInstance();

            try {
              // Wait for image processing to complete
              await imageService.processImageMessage(
                message.id,
                lineIntegration.channelAccessToken,
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                chatHistoryId,
              );
              console.log("‚úÖ Image processing completed successfully");

              // Get the SPECIFIC image analysis for THIS message
              const updatedChatHistory = await storage.getChatHistory(
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                10, // Get more messages to find the right analysis
              );

              // Find the image analysis that corresponds to THIS specific message
              const imageAnalysisMessage = updatedChatHistory.find(
                (msg) =>
                  msg.messageType === "system" &&
                  msg.metadata?.messageType === "image_analysis" &&
                  msg.metadata?.relatedImageMessageId === message.id,
              );

              if (imageAnalysisMessage) {
                const imageAnalysisResult =
                  imageAnalysisMessage.content.replace(
                    "[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ",
                    "",
                  );
                console.log(
                  `üîç Found specific image analysis for message ${message.id}: ${imageAnalysisResult.substring(0, 100)}...`,
                );

                // 3. Generate AI response with image analysis
                const contextMessage = `‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤ ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:

${imageAnalysisResult}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠`;

                const aiResponse = await getAiResponseDirectly(
                  contextMessage,
                  lineIntegration.agentId,
                  lineIntegration.userId,
                  "lineoa",
                  event.source.userId,
                );

                // 4. Send follow-up message with AI analysis
                await sendLinePushMessage(
                  event.source.userId,
                  aiResponse,
                  lineIntegration.channelAccessToken,
                );

                // Save the assistant response
                await storage.createChatHistory({
                  userId: lineIntegration.userId,
                  channelType: "lineoa",
                  channelId: event.source.userId,
                  agentId: lineIntegration.agentId,
                  messageType: "assistant",
                  content: aiResponse,
                  metadata: { relatedImageMessageId: message.id },
                });

                console.log("‚úÖ Image analysis response sent successfully");
              } else {
                console.log(
                  "‚ö†Ô∏è No specific image analysis found for this message",
                );
                await sendLinePushMessage(
                  event.source.userId,
                  "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                  lineIntegration.channelAccessToken,
                );
              }
            } catch (error) {
              console.error("‚ö†Ô∏è Error processing image message:", error);
              await sendLinePushMessage(
                event.source.userId,
                "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                lineIntegration.channelAccessToken,
              );
            }
          }

          // Broadcast to WebSocket for real-time updates
          if (typeof (global as any).broadcastToAgentConsole === "function") {
            (global as any).broadcastToAgentConsole({
              type: "new_message",
              data: {
                userId: lineIntegration.userId,
                channelType: "lineoa",
                channelId: event.source.userId,
                agentId: lineIntegration.agentId,
                userMessage: userMessage,
                aiResponse: "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß ‡∏Ç‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ô‡∏∞‡∏Ñ‡∏∞",
                timestamp: new Date().toISOString(),
              },
            });
          }

          // Skip normal AI response processing for images
          continue;
        }

        // Get AI response with chat history (only for text messages or provide context for multimedia)
        if (lineIntegration.agentId) {
          let contextMessage = userMessage;

          if (message.type === "sticker") {
            contextMessage =
              "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏°‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢";
          }

        // Get agent's documents for proper scope restriction
        const agentDocs = await storage.getAgentChatbotDocuments(
          lineIntegration.agentId,
          lineIntegration.userId,
        );
        console.log(
          `LINE OA: Found ${agentDocs.length} assigned documents for agent ${lineIntegration.agentId}`,
        );

        // === CONVERSATIONAL KEYWORD OPTIMIZATION ===
        // Get recent chat history for keyword optimization
        let optimizedSearchQuery = contextMessage;
        try {
          console.log(`üîç LINE OA: Starting conversational keyword optimization for: "${contextMessage}"`);

          // Get recent chat history (last 10 messages)
          const recentChatHistory = await storage.getChatHistory(
            lineIntegration.userId,
            "lineoa",
            event.source.userId,
            lineIntegration.agentId,
            10
          );

          if (recentChatHistory.length > 0) {
            const { conversationalKeywordOptimizer } = await import("./services/conversationalKeywordOptimizer");

            // Extract conversation context
            const conversationContext = conversationalKeywordOptimizer.extractConversationContext(recentChatHistory);

            // Optimize keywords based on conversation context
            const optimization = await conversationalKeywordOptimizer.optimizeKeywords(
              contextMessage,
              conversationContext,
              8 // Use last 8 messages for context
            );

            if (optimization.confidence >= 0.6) {
              optimizedSearchQuery = optimization.searchQuery;
              console.log(`‚úÖ LINE OA: Keyword optimization successful!`);
              console.log(`   üìù Original query: "${contextMessage}"`);
              console.log(`   üéØ Optimized query: "${optimizedSearchQuery}"`);
              console.log(`   üîß Keywords: [${optimization.optimizedKeywords.join(', ')}]`);
              console.log(`   üìä Confidence: ${optimization.confidence}`);
              console.log(`   üí≠ Reasoning: ${optimization.reasoning}`);
            } else {
              console.log(`‚ö†Ô∏è LINE OA: Low confidence (${optimization.confidence}), using original query`);
            }
          } else {
            console.log(`‚ÑπÔ∏è LINE OA: No chat history available for keyword optimization`);
          }
        } catch (optimizationError) {
          console.error("‚ö†Ô∏è LINE OA: Keyword optimization failed:", optimizationError);
          console.log(`üîÑ LINE OA: Falling back to original query: "${contextMessage}"`);
        }

          // Convert agent docs to format expected by generateChatResponse
          const agentDocuments = [];
          for (const agentDoc of agentDocs) {
            try {
              const document = await storage.getDocument(
                agentDoc.documentId,
                lineIntegration.userId,
              );
              if (document) {
                agentDocuments.push({
                  ...document,
                  userId: lineIntegration.userId,
                });
              }
            } catch (error) {
              console.error(
                `LINE OA: Error fetching document ${agentDoc.documentId}:`,
                error,
              );
            }
          }

          console.log(
            `LINE OA: Using ${agentDocuments.length} documents for hybrid search`,
          );

          // Use hybrid search with document scope restriction like debug routes
          const { semanticSearchV2 } = await import(
            "./services/semanticSearchV2"
          );
          let aiResponse = "";

          try {
            // Ensure agentDocIds is defined before using it
            const agentDocIds = agentDocs.map((d) => d.documentId);
            console.log(
              `LINE OA: Performing hybrid search with document restriction to ${agentDocIds.length} documents: [${agentDocIds.join(", ")}]`,
            );

            // Use hybrid search with proper document filtering - same as debug page
            const searchResults = await semanticSearchV2.hybridSearch(
              contextMessage,
              lineIntegration.userId,
              {
                keywordWeight: 0.4,
                vectorWeight: 0.6,
                limit: 100, // Get arbitrarily large number of results
                specificDocumentIds: agentDocIds, // Restrict to agent's documents only
              },
            );

            console.log(
              `LINE OA: Hybrid search found ${searchResults.length} relevant chunks from agent's documents`,
            );

            if (searchResults.length > 0) {
              // Step 1: Pool ALL chunks from ALL documents together and filter by similarity threshold
              const allChunks = [];

              for (const result of searchResults) {
                // Only include chunks with similarity >= 0.25
                if (result.similarity >= 0.25) {
                  allChunks.push({
                    docName: result.document.name,
                    content: result.content,
                    similarity: result.similarity,
                  });
                }
              }

              console.log(
                `LINE OA: Filtered to ${allChunks.length} chunks above 0.25 similarity threshold from ${agentDocIds.length} agent documents`,
              );

              // Step 2: Sort ALL chunks globally by similarity and use ALL chunks above threshold (not limited to 5)
              allChunks.sort((a, b) => b.similarity - a.similarity);
              const finalChunks = allChunks; // Use ALL chunks that passed the similarity threshold

              console.log(
                `LINE OA: Using all ${finalChunks.length} chunks above similarity threshold:`,
              );
              finalChunks.forEach((chunk, idx) => {
                console.log(
                  `  ${idx + 1}. ${chunk.docName} - Similarity: ${chunk.similarity.toFixed(4)}`,
                );
                console.log(
                  `      Content preview: ${chunk.content.substring(0, 100)}...`,
                );
              });

              // Build context with string length limit as final safeguard
              let documentContext = "";
              const maxContextLength = 50000; // Increased limit to accommodate more chunks

              for (let i = 0; i < finalChunks.length; i++) {
                const chunk = finalChunks[i];
                const chunkText = `=== ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà ${i + 1}: ${chunk.docName} ===\n‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ${chunk.similarity.toFixed(3)}\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ${chunk.content}\n\n`;

                // Check if adding this chunk would exceed the limit
                if (
                  documentContext.length + chunkText.length <=
                  maxContextLength
                ) {
                  documentContext += chunkText;
                } else {
                  // Truncate the chunk to fit within limit
                  const remainingSpace =
                    maxContextLength - documentContext.length;
                  if (remainingSpace > 200) {
                    // Only add if there's meaningful space
                    const truncatedContent =
                      chunk.content.substring(0, remainingSpace - 150) + "...";
                    documentContext += `=== ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà ${i + 1}: ${chunk.docName} ===\n‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: ${chunk.similarity.toFixed(3)}\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ${truncatedContent}\n\n`;
                  }
                  break;
                }
              }

              console.log(
                `LINE OA: Final context length: ${documentContext.length} characters (limit: ${maxContextLength}, used ${finalChunks.length} chunks)`,
              );

              // Generate AI response with focused document context
              // Use existing OpenAI instance from module scope

              const agent = await storage.getAgentChatbot(
                lineIntegration.agentId,
                lineIntegration.userId,
              );
              const systemPrompt = `${agent?.systemPrompt || "You are a helpful assistant."}

‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á):
${documentContext}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô`;

              console.log(
                `LINE OA: System prompt length: ${systemPrompt.length} characters`,
              );

              const completion = await openai.chat.completions.create({
                model: "gpt-4o",
                messages: [
                  { role: "system", content: systemPrompt },
                  { role: "user", content: contextMessage },
                ],
                max_tokens: 1000,
                temperature: 0.7,
              });

              aiResponse =
                completion.choices[0].message.content ||
                "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";
              console.log(
                `‚úÖ LINE OA: Generated response using ${finalChunks.length} chunks above similarity threshold (${aiResponse.length} chars)`,
              );
            } else {
              console.log(
                `‚ö†Ô∏è LINE OA: No relevant content found in agent's documents, using system prompt only`,
              );
              // Fallback to system prompt conversation
              aiResponse = await getAiResponseDirectly(
                contextMessage,
                lineIntegration.agentId,
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
              );
            }
          } catch (error) {
            console.error(
              "LINE OA: Hybrid search failed, using fallback:",
              error,
            );
            // Fallback to agent conversation without documents
            aiResponse = await getAiResponseDirectly(
              contextMessage,
              lineIntegration.agentId,
              lineIntegration.userId,
              "lineoa",
              event.source.userId, // Use Line user ID as channel identifier
            );
          }
          console.log("ü§ñ AI response:", aiResponse);

          // Save only the assistant response (user message already saved above)
          try {
            await storage.createChatHistory({
              userId: lineIntegration.userId,
              channelType: "lineoa",
              channelId: event.source.userId,
              agentId: lineIntegration.agentId,
              messageType: "assistant",
              content: aiResponse,
              metadata: {},
            });
            console.log("üíæ Saved AI response to chat history");

            // Broadcast new message to Agent Console via WebSocket
            if (typeof (global as any).broadcastToAgentConsole === "function") {
              (global as any).broadcastToAgentConsole({
                type: "new_message",
                data: {
                  userId: lineIntegration.userId,
                  channelType: "lineoa",
                  channelId: event.source.userId,
                  agentId: lineIntegration.agentId,
                  userMessage: contextMessage,
                  aiResponse,
                  timestamp: new Date().toISOString(),
                },
              });
              console.log("üì° Broadcasted new message to Agent Console");
            }
          } catch (error) {
            console.error("‚ö†Ô∏è Error saving AI response:", error);
          }

          // Send reply to Line using stored access token
          if (lineIntegration.channelAccessToken) {
            await sendLineReply(
              replyToken,
              aiResponse,
              lineIntegration.channelAccessToken,
            );
          } else {
            console.log(
              "‚ùå No channel access token available for Line integration",
            );
            await sendLineReply(
              replyToken,
              "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ access token ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
              lineIntegration.channelSecret!,
            );
          }
        } else {
          await sendLineReply(
            replyToken,
            "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI Agent ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
            lineIntegration.channelSecret!,
          );
        }
      }
    }

    res.status(200).json({ status: "ok" });
  } catch (error) {
    console.error("üí• Line webhook error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
}