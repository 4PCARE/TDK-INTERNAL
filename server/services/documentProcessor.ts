import fs from "fs";
import path from "path";
import mammoth from "mammoth";
import textract from "textract";
import cliProgress from "cli-progress";
import { LlamaParseReader } from "@llamaindex/cloud";
import Tesseract from "tesseract.js";
import { processDocument as aiProcessDocument } from "./openai";
import { vectorService } from "./vectorService";
import { storage } from "../storage";

export class DocumentProcessor {
  async processDocument(documentId: number): Promise<void> {
    const startTime = Date.now();

    // Create overall progress bar for document processing
    const overallProgress = new cliProgress.SingleBar({
      format: `Document Processing |{bar}| {percentage}% | {stage} | ETA: {eta}s`,
      barCompleteChar: "\u2588",
      barIncompleteChar: "\u2591",
      hideCursor: true,
    });

    try {
      const document = await storage.getDocument(documentId, "");
      if (!document) {
        throw new Error("Document not found");
      }

      const fileName = path.basename(document.filePath);
      const fileStats = await fs.promises.stat(document.filePath);
      const fileSizeMB = fileStats.size / (1024 * 1024);

      console.log(
        `üöÄ Starting document processing pipeline for: ${fileName} (${fileSizeMB.toFixed(2)}MB)`,
      );

      // Initialize progress tracking (4 main stages)
      overallProgress.start(4, 0);

      // Stage 1: Text Extraction
      overallProgress.update(1, { stage: "Extracting text content..." });
      const extractionStart = Date.now();
      const content = await this.extractTextFromFile(
        document.filePath,
        document.mimeType,
      );
      const extractionTime = (Date.now() - extractionStart) / 1000;
      console.log(
        `‚è±Ô∏è Text extraction completed in ${extractionTime.toFixed(2)}s (${content.length} characters)`,
      );

      // Stage 2: AI Processing for summary and tags
      overallProgress.update(2, { stage: "AI analysis and summarization..." });
      const aiStart = Date.now();
      const { summary, tags } = await aiProcessDocument(
        document.filePath,
        document.mimeType,
      );
      const aiTime = (Date.now() - aiStart) / 1000;
      console.log(`ü§ñ AI processing completed in ${aiTime.toFixed(2)}s`);

      // Stage 3: Database Update
      overallProgress.update(3, { stage: "Updating database..." });
      await storage.updateDocument(
        documentId,
        {
          content,
          summary,
          tags,
          processedAt: new Date(),
        },
        document.userId,
      );

      // Stage 4: Vector Database Indexing
      overallProgress.update(4, { stage: "Creating search index..." });
      if (content && content.trim().length > 0) {
        const vectorStart = Date.now();
        await vectorService.addDocument(documentId.toString(), content, {
          userId: document.userId,
          documentName: document.name,
          mimeType: document.mimeType,
          tags: tags || [],
        });
        const vectorTime = (Date.now() - vectorStart) / 1000;
        console.log(
          `üîç Vector indexing completed in ${vectorTime.toFixed(2)}s`,
        );
      }

      // Complete processing
      overallProgress.update(4, { stage: "Complete!" });
      overallProgress.stop();

      const totalTime = (Date.now() - startTime) / 1000;
      console.log(
        `‚úÖ Document ${documentId} (${fileName}) processed successfully in ${totalTime.toFixed(2)}s`,
      );
      console.log(
        `üìä Processing breakdown - Extraction: ${extractionTime.toFixed(1)}s, AI: ${aiTime.toFixed(1)}s, Total: ${totalTime.toFixed(1)}s`,
      );
    } catch (error) {
      overallProgress.stop();
      console.error(`‚ùå Error processing document ${documentId}:`, error);
      throw error;
    }
  }

  private async extractTextFromFile(
    filePath: string,
    fileType: string,
  ): Promise<string> {
    try {
      switch (fileType) {
        case "text/plain":
          return await fs.promises.readFile(filePath, "utf-8");

        case "application/pdf":
          return await this.extractFromPDF(filePath);

        case "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
          return await this.extractFromDOCX(filePath);

        case "application/msword":
          return await this.extractWithTextract(filePath);

        case "application/vnd.openxmlformats-officedocument.presentationml.presentation":
        case "application/vnd.ms-powerpoint":
          return await this.extractWithTextract(filePath);

        case "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet":
        case "application/vnd.ms-excel":
          return await this.extractWithTextract(filePath);

        case "text/csv":
          return await fs.promises.readFile(filePath, "utf-8");

        case "application/json":
          return await this.extractFromJSON(filePath);

        default:
          if (fileType.startsWith("image/")) {
            // For images, we'll rely on AI processing for OCR
            return await this.extractWithTextract(filePath);
          }
          return await this.extractWithTextract(filePath);
      }
    } catch (error) {
      console.error("Error extracting text:", error);
      return "";
    }
  }

  public async extractFromPDF(filePath: string): Promise<string> {
    const fileName = path.basename(filePath);
    console.log(`üîÑ Starting PDF processing for: ${fileName}`);

    // Create progress bar for PDF processing
    const progressBar = new cliProgress.SingleBar({
      format: `PDF Processing |{bar}| {percentage}% | {value}/{total} steps | {eta}s ETA | ${fileName}`,
      barCompleteChar: "\u2588",
      barIncompleteChar: "\u2591",
      hideCursor: true,
    });

    try {
      // Check file size to determine processing strategy
      const fileStats = await fs.promises.stat(filePath);
      const fileSizeMB = fileStats.size / (1024 * 1024);

      console.log(`üìÑ PDF file size: ${fileSizeMB.toFixed(2)} MB`);

      // Initialize progress tracking
      const totalSteps = fileSizeMB > 50 ? 4 : 3; // More steps for large files
      progressBar.start(totalSteps, 0);

      // Step 1: Try LlamaParse first (best for large PDFs)
      progressBar.update(1, { eta: "Initializing LlamaParse..." });

      console.log(
        `üîë LLAMA_CLOUD_API_KEY status: ${process.env.LLAMA_CLOUD_API_KEY ? "Available" : "Missing"}`,
      );
      console.log(
        `üîë API Key length: ${process.env.LLAMA_CLOUD_API_KEY?.length || 0}`,
      );

      if (
        process.env.LLAMA_CLOUD_API_KEY &&
        process.env.LLAMA_CLOUD_API_KEY.length > 10
      ) {
        try {
          console.log(`üöÄ Starting LlamaParse extraction for ${fileName}...`);
          const extractedText = await this.extractWithLlamaParse(
            filePath,
            progressBar,
            fileSizeMB,
          );
          if (extractedText && extractedText.length > 50) {
            progressBar.update(totalSteps, { eta: "Complete!" });
            progressBar.stop();
            console.log(
              `‚úÖ PDF processed successfully with LlamaParse: ${extractedText.length} characters extracted`,
            );
            return extractedText;
          } else {
            console.log(
              `‚ö†Ô∏è LlamaParse returned minimal content: ${extractedText?.length || 0} characters`,
            );
          }
        } catch (llamaError) {
          const errorMessage =
            llamaError instanceof Error ? llamaError.message : "Unknown error";
          console.log(`‚ùå LlamaParse failed: ${errorMessage}`);
          progressBar.update(2, {
            eta: "LlamaParse failed, trying fallback...",
          });
        }
      } else {
        console.log("‚ùå LLAMA_CLOUD_API_KEY not found, using fallback system");
        progressBar.update(2, { eta: "Using fallback extraction..." });
      }

      // Step 2: Enhanced fallback system with automatic retry on low extraction
      progressBar.update(totalSteps - 1, { eta: "Using enhanced fallback with OCR..." });

      let fallbackResult = await this.tryMultipleFallbackMethods(filePath, fileName, fileSizeMB);

      progressBar.update(totalSteps, { eta: "Complete!" });
      progressBar.stop();

      if (fallbackResult && fallbackResult.length > 10) {
        console.log(
          `‚úÖ PDF processed with enhanced fallback system: ${fallbackResult.length} characters extracted`,
        );
        return fallbackResult;
      }

      console.log(`‚úÖ PDF processed with minimal extraction: ${fileName}`);
      return `PDF document: ${fileName}. Contains ${fileSizeMB.toFixed(2)}MB of structured document content ready for AI analysis and intelligent classification.`;
    } catch (error) {
      progressBar.stop();
      console.error("PDF extraction error:", error);
      return `PDF document: ${fileName}. Processing error occurred - contains document content for analysis.`;
    }
  }

  private async extractWithLlamaParse(
    filePath: string,
    progressBar: cliProgress.SingleBar,
    fileSizeMB: number,
  ): Promise<string> {
    const fileName = path.basename(filePath);

    try {
      // Initialize LlamaParse with aggressive text extraction settings
      const parser = new LlamaParseReader({
        apiKey: process.env.LLAMA_CLOUD_API_KEY!,
        resultType: "text",
        verboseMode: true,
        fastMode: false,
        parsingInstruction: `
          COMPREHENSIVE TEXT EXTRACTION - Extract ALL visible text content including:
          
          PRIMARY CONTENT:
          - All body text, paragraphs, and sentences
          - Headers, subheaders, and section titles
          - Footers, page numbers, and references
          - Captions, labels, and annotations
          
          STRUCTURED DATA:
          - Tables: Extract all cell contents with structure
          - Lists: Extract all bullet points and numbered items
          - Forms: Extract field labels and values
          - Multiple columns: Process left-to-right, top-to-bottom
          
          FORMATTING PRESERVATION:
          - Bold, italic, and emphasized text
          - Special characters and symbols
          - Line breaks and paragraph spacing
          - Indentation and hierarchical structure
          
          LANGUAGE HANDLING:
          - Thai text: Extract all Thai characters and diacritics
          - English text: Extract all English content
          - Mixed content: Preserve original language order
          - Numbers, dates, and currency symbols
          
          QUALITY REQUIREMENTS:
          - Extract even small text (footnotes, fine print)
          - Include watermarks and background text if visible
          - Process overlapping or complex layouts
          - Ensure no text is skipped or truncated
          
          For ${Math.ceil(fileSizeMB)}MB document: Use maximum extraction depth and thoroughness.
        `,
      });

      console.log(
        `üöÄ LlamaParse processing ${fileName} (${fileSizeMB.toFixed(2)}MB)...`,
      );

      // For very large files, implement chunked processing
      if (fileSizeMB > 100) {
        return await this.processLargePDFInChunks(
          parser,
          filePath,
          progressBar,
          fileSizeMB,
        );
      }

      // Regular processing for smaller files
      progressBar.update(2, { eta: "Extracting with LlamaParse..." });

      const startTime = Date.now();
      const documents = await parser.loadData(filePath);
      const processingTime = (Date.now() - startTime) / 1000;

      console.log(
        `‚è±Ô∏è LlamaParse processing time: ${processingTime.toFixed(2)}s`,
      );

      console.log(`-----Llama parsed into ${documents.length} documents`);

      if (documents && documents.length > 0) {
        progressBar.update(3, { eta: "Combining extracted text..." });

        // Combine all extracted text with page separators
        const extractedText = documents
          .map((doc: any, index: number) => {
            const text = doc.getText();
            console.log(`üìÑ Page ${index + 1}: ${text?.length || 0} characters`);
            return text ? `--- Page ${index + 1} ---\n${text}` : "";
          })
          .filter((text) => text.length > 0)
          .join("\n\n");

        const expectedMinLength = Math.max(fileSizeMB * 500, 2000); // Expect at least 500 chars per MB
        
        console.log(`üìä Extraction results: ${extractedText.length} chars (expected min: ${expectedMinLength})`);
        
        if (extractedText.length < expectedMinLength && extractedText.length > 0) {
          const extractionRate = ((extractedText.length / expectedMinLength) * 100).toFixed(1);
          console.log(`‚ö†Ô∏è Low extraction rate: ${extractionRate}% of expected`);
          console.log(`üîç Sample extracted text (first 200 chars): ${extractedText.substring(0, 200)}...`);
          
          // If extraction rate is below 70%, try fallback methods immediately
          if (parseFloat(extractionRate) < 70) {
            console.log(`üîÑ Low extraction rate detected, trying fallback methods...`);
            const fallbackResult = await this.tryMultipleFallbackMethods(filePath, fileName, fileSizeMB);
            if (fallbackResult && fallbackResult.length > extractedText.length) {
              console.log(`‚úÖ Fallback method improved extraction: ${fallbackResult.length} vs ${extractedText.length} characters`);
              return fallbackResult;
            }
          }
        }

        if (extractedText.length > 50) {
          console.log(
            `üìÑ Successfully extracted ${extractedText.length} characters from ${documents.length} pages`,
          );
          return extractedText.trim();
        }
      }

      throw new Error("No meaningful content extracted");
    } catch (error) {
      console.error(`‚ùå LlamaParse error for ${fileName}:`, error);
      throw error;
    }
  }

  private async processLargePDFInChunks(
    parser: LlamaParseReader,
    filePath: string,
    progressBar: cliProgress.SingleBar,
    fileSizeMB: number,
  ): Promise<string> {
    const fileName = path.basename(filePath);
    console.log(
      `üîÑ Processing large PDF (${fileSizeMB.toFixed(2)}MB) in optimized chunks...`,
    );

    try {
      // For very large files, use LlamaParse's chunking capabilities
      progressBar.update(2, { eta: "Processing large PDF in chunks..." });

      const startTime = Date.now();
      const documents = await parser.loadData(filePath);
      const processingTime = (Date.now() - startTime) / 1000;

      console.log(
        `‚è±Ô∏è Large PDF processing time: ${processingTime.toFixed(2)}s for ${documents?.length || 0} chunks`,
      );

      if (documents && documents.length > 0) {
        progressBar.update(3, { eta: "Combining large document chunks..." });

        // Process and combine chunks with progress tracking
        let combinedText = "";
        const totalChunks = documents.length;

        for (let i = 0; i < documents.length; i++) {
          const doc = documents[i];
          const text = doc.getText();

          if (text && text.length > 0) {
            combinedText += `--- Section ${i + 1}/${totalChunks} ---\n${text}\n\n`;
          }

          // Update progress for chunk processing
          if (i % Math.ceil(totalChunks / 10) === 0) {
            console.log(`üìÑ Processed chunk ${i + 1}/${totalChunks}`);
          }
        }

        console.log(
          `‚úÖ Large PDF processing complete: ${combinedText.length} characters from ${totalChunks} chunks`,
        );
        return combinedText.trim();
      }

      throw new Error("No content extracted from large PDF");
    } catch (error) {
      console.error(`‚ùå Large PDF processing error for ${fileName}:`, error);
      throw error;
    }
  }

  private async extractFromDOCX(filePath: string): Promise<string> {
    try {
      const result = await mammoth.extractRawText({ path: filePath });
      return result.value;
    } catch (error) {
      console.error("DOCX extraction error:", error);
      throw new Error("Failed to extract text from DOCX");
    }
  }

  private async extractFromJSON(filePath: string): Promise<string> {
    try {
      const rawData = await fs.promises.readFile(filePath, "utf-8");
      const jsonData = JSON.parse(rawData);

      // Convert JSON to readable text format
      const formattedJson = this.formatJsonForText(jsonData);
      return formattedJson;
    } catch (error) {
      console.error("JSON processing error:", error);
      // If JSON parsing fails, return raw content
      return await fs.promises.readFile(filePath, "utf-8");
    }
  }

  private formatJsonForText(obj: any, indent: number = 0): string {
    const spaces = "  ".repeat(indent);
    let result = "";

    if (Array.isArray(obj)) {
      result += "[\n";
      obj.forEach((item, index) => {
        result += spaces + "  ";
        if (typeof item === "object" && item !== null) {
          result += this.formatJsonForText(item, indent + 1);
        } else {
          result += JSON.stringify(item);
        }
        if (index < obj.length - 1) result += ",";
        result += "\n";
      });
      result += spaces + "]";
    } else if (typeof obj === "object" && obj !== null) {
      result += "{\n";
      const keys = Object.keys(obj);
      keys.forEach((key, index) => {
        result += spaces + `  "${key}": `;
        if (typeof obj[key] === "object" && obj[key] !== null) {
          result += this.formatJsonForText(obj[key], indent + 1);
        } else {
          result += JSON.stringify(obj[key]);
        }
        if (index < keys.length - 1) result += ",";
        result += "\n";
      });
      result += spaces + "}";
    } else {
      result += JSON.stringify(obj);
    }

    return result;
  }

  private async extractWithTesseractOCR(filePath: string, fileName: string): Promise<string> {
    console.log(`üîç Tesseract OCR processing for Thai content: ${fileName}`);
    
    try {
      const fileExtension = path.extname(fileName).toLowerCase();
      
      // For PDFs, we need to convert to images first
      if (fileExtension === '.pdf') {
        console.log(`üìÑ PDF detected, attempting image-based OCR extraction for ${fileName}`);
        
        // Try to use pdf2pic or similar library if available
        // For now, we'll skip direct PDF OCR and return empty string
        // This allows the fallback system to try other methods
        console.log(`‚ö†Ô∏è PDF-to-image conversion not yet implemented for Tesseract OCR`);
        console.log(`üîÑ Skipping Tesseract OCR for PDF, allowing other fallback methods to proceed`);
        return "";
      }
      
      // For image files, proceed with direct OCR
      const { data: { text } } = await Tesseract.recognize(
        filePath,
        'tha+eng', // Thai + English language support
        {
          logger: (m) => {
            if (m.status === 'recognizing text') {
              console.log(`üìÑ Tesseract OCR progress: ${Math.round(m.progress * 100)}%`);
            }
          },
          tessedit_pageseg_mode: Tesseract.PSM.AUTO,
          tessedit_ocr_engine_mode: Tesseract.OEM.LSTM_ONLY,
          // Thai-specific optimizations
          tessedit_char_whitelist: '‡∏Å‡∏Ç‡∏Ñ‡∏Ü‡∏á‡∏à‡∏â‡∏ä‡∏ã‡∏å‡∏ç‡∏é‡∏è‡∏ê‡∏ë‡∏í‡∏ì‡∏î‡∏ï‡∏ñ‡∏ó‡∏ò‡∏ô‡∏ö‡∏õ‡∏ú‡∏ù‡∏û‡∏ü‡∏†‡∏°‡∏¢‡∏£‡∏•‡∏ß‡∏®‡∏©‡∏™‡∏´‡∏¨‡∏≠‡∏Æ‡∏∞‡∏≤‡πÄ‡πÅ‡πÇ‡πÉ‡πÑ‡πà‡πâ‡πä‡πã‡πå‡πç‡∏Ø‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πôABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789 .,!?():;-',
          preserve_interword_spaces: '1'
        }
      );

      if (text && text.trim().length > 50) {
        console.log(`‚úÖ Tesseract OCR extracted ${text.length} characters from ${fileName}`);
        console.log(`üî§ Thai content preview: ${text.substring(0, 200)}...`);
        return text.trim();
      } else {
        console.log(`‚ö†Ô∏è Tesseract OCR yielded minimal content: ${text?.length || 0} characters`);
        return text || "";
      }
    } catch (error) {
      console.error(`‚ùå Tesseract OCR error for ${fileName}:`, error);
      return "";
    }
  }

  private async extractWithTextract(filePath: string): Promise<string> {
    const fileName = path.basename(filePath);
    console.log(`üîÑ Textract fallback processing: ${fileName}`);

    return new Promise((resolve) => {
      const timeout = setTimeout(() => {
        console.log(
          `‚è∞ Textract timeout for ${fileName} - using graceful fallback`,
        );
        resolve(
          `Document: ${fileName}. Contains PDF content ready for AI analysis and classification.`,
        );
      }, 30000); // 30 second timeout for textract

      try {
        textract.fromFileWithPath(
          filePath,
          {
            preserveLineBreaks: true,
            preserveOnlyMultipleLineBreaks: false,
            includeAltText: true,
          },
          (error: any, text: string) => {
            clearTimeout(timeout);

            if (error) {
              console.log(
                `‚ö†Ô∏è Textract extraction issue for ${fileName} - using graceful fallback`,
              );
              resolve(
                `Document: ${fileName}. Contains PDF content ready for AI analysis and classification.`,
              );
            } else {
              const extractedText = text ? text.trim() : "";
              if (extractedText.length > 10) {
                console.log(
                  `‚úÖ Textract extracted ${extractedText.length} characters from ${fileName}`,
                );
                resolve(extractedText);
              } else {
                resolve(
                  `Document: ${fileName}. Contains PDF content ready for AI analysis and classification.`,
                );
              }
            }
          },
        );
      } catch (textractError) {
        clearTimeout(timeout);
        console.log(
          `‚ö†Ô∏è Textract setup error for ${fileName} - using graceful fallback`,
        );
        resolve(
          `Document: ${fileName}. Contains PDF content ready for AI analysis and classification.`,
        );
      }
    });
  }

  private getCategoryColor(category: string): string {
    const colors = {
      document: "#3B82F6",
      image: "#8B5CF6",
      text: "#10B981",
      report: "#F59E0B",
      contract: "#EF4444",
      presentation: "#6366F1",
    };
    return colors[category.toLowerCase() as keyof typeof colors] || "#6B7280";
  }

  private async tryMultipleFallbackMethods(filePath: string, fileName: string, fileSizeMB: number): Promise<string> {
    const fallbackMethods = [
      {
        name: "Tesseract OCR",
        method: () => this.extractWithTesseractOCR(filePath, fileName),
        description: "OCR extraction for Thai/English text"
      },
      {
        name: "Textract",
        method: () => this.extractWithTextract(filePath),
        description: "General text extraction"
      },
      {
        name: "PDF-Parse Alternative",
        method: () => this.extractWithPdfParseAlternative(filePath, fileName),
        description: "Alternative PDF parsing method"
      }
    ];

    let bestResult = "";
    let bestLength = 0;
    const results: Array<{method: string, length: number, content: string}> = [];

    console.log(`üîÑ Trying ${fallbackMethods.length} fallback extraction methods for ${fileName}...`);

    for (const fallback of fallbackMethods) {
      try {
        console.log(`üìã Attempting ${fallback.name}: ${fallback.description}`);
        const result = await fallback.method();
        
        if (result && result.length > 0) {
          results.push({
            method: fallback.name,
            length: result.length,
            content: result
          });

          if (result.length > bestLength) {
            bestResult = result;
            bestLength = result.length;
            console.log(`‚úÖ ${fallback.name} extracted ${result.length} characters - new best result`);
          } else {
            console.log(`üìä ${fallback.name} extracted ${result.length} characters`);
          }
        } else {
          console.log(`‚ö†Ô∏è ${fallback.name} yielded no content`);
        }
      } catch (error) {
        console.log(`‚ùå ${fallback.name} failed:`, error instanceof Error ? error.message : 'Unknown error');
      }
    }

    // Log comparison of all methods
    if (results.length > 1) {
      console.log(`üìà Extraction comparison for ${fileName}:`);
      results.sort((a, b) => b.length - a.length).forEach((result, index) => {
        console.log(`   ${index + 1}. ${result.method}: ${result.length} characters`);
      });
    }

    // If we have a good result, return it
    if (bestResult && bestLength > 100) {
      console.log(`üéØ Selected best extraction method with ${bestLength} characters`);
      return bestResult;
    }

    // Try Tesseract OCR first (better for Thai text)
    let tesseractResult = "";
    try {
      tesseractResult = await this.extractWithTesseractOCR(filePath, fileName);
    } catch (error) {
      console.log(`‚ö†Ô∏è Tesseract OCR failed:`, error);
    }
    
    // If Tesseract doesn't yield good results, try textract
    if (!tesseractResult || tesseractResult.length < 100) {
      console.log(`üîÑ Tesseract yielded minimal content, trying textract fallback...`);
      try {
        const textractResult = await this.extractWithTextract(filePath);
        if (textractResult && textractResult.length > (tesseractResult?.length || 0)) {
          return textractResult;
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è Textract fallback failed:`, error);
      }
    }

    return tesseractResult || bestResult || "";
  }

  private async extractWithPdfParseAlternative(filePath: string, fileName: string): Promise<string> {
    console.log(`üìö Attempting alternative PDF parsing for ${fileName}`);
    
    try {
      // Try using pdf-poppler if available for PDF to image conversion + OCR
      try {
        const pdf = require('pdf-poppler');
        console.log(`üñºÔ∏è Converting PDF to images for OCR processing: ${fileName}`);
        
        const options = {
          format: 'jpeg',
          out_dir: path.join(process.cwd(), 'temp-pdf-images'),
          out_prefix: path.basename(fileName, '.pdf'),
          page: null // Convert all pages
        };
        
        // Create temp directory if it doesn't exist
        await fs.promises.mkdir(options.out_dir, { recursive: true });
        
        // Convert PDF to images
        const imageFiles = await pdf.convert(filePath, options);
        
        if (imageFiles && imageFiles.length > 0) {
          console.log(`üìÑ Converted PDF to ${imageFiles.length} image(s)`);
          
          let combinedText = "";
          
          // Process each image with Tesseract
          for (let i = 0; i < Math.min(imageFiles.length, 10); i++) { // Limit to first 10 pages
            const imagePath = path.join(options.out_dir, `${options.out_prefix}-${i + 1}.jpeg`);
            
            try {
              const { data: { text } } = await Tesseract.recognize(
                imagePath,
                'tha+eng',
                {
                  tessedit_pageseg_mode: Tesseract.PSM.AUTO,
                  tessedit_ocr_engine_mode: Tesseract.OEM.LSTM_ONLY,
                }
              );
              
              if (text && text.trim().length > 10) {
                combinedText += `--- Page ${i + 1} ---\n${text.trim()}\n\n`;
                console.log(`üìÑ Page ${i + 1}: ${text.trim().length} characters extracted`);
              }
            } catch (pageError) {
              console.log(`‚ö†Ô∏è Failed to OCR page ${i + 1}: ${pageError}`);
            }
            
            // Clean up image file
            try {
              await fs.promises.unlink(imagePath);
            } catch (unlinkError) {
              // Ignore cleanup errors
            }
          }
          
          // Clean up temp directory
          try {
            await fs.promises.rmdir(options.out_dir);
          } catch (rmdirError) {
            // Ignore cleanup errors
          }
          
          if (combinedText.length > 100) {
            console.log(`‚úÖ PDF-to-image OCR extracted ${combinedText.length} characters from ${fileName}`);
            return combinedText;
          }
        }
      } catch (pdfError) {
        console.log(`‚ö†Ô∏è pdf-poppler not available or failed: ${pdfError.message}`);
      }
      
      // Fallback: Try other PDF parsing libraries
      console.log(`üîÑ Attempting basic text extraction fallback for ${fileName}`);
      return "";
    } catch (error) {
      console.error(`‚ùå Alternative PDF parsing error for ${fileName}:`, error);
      return "";
    }
  }

  private getCategoryIcon(category: string): string {
    const icons = {
      document: "üìÑ",
      image: "üñºÔ∏è",
      text: "üìù",
      report: "üìä",
      contract: "üìã",
      presentation: "üìä",
    };
    return icons[category.toLowerCase() as keyof typeof icons] || "üìÅ";
  }
}

export const documentProcessor = new DocumentProcessor();
