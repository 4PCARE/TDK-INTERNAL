import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export interface QueryAnalysis {
  needsSearch: boolean;
  enhancedQuery: string;
  keywordWeight: number;
  vectorWeight: number;
  reasoning: string;
}

export interface ChatMessage {
  messageType: 'user' | 'assistant';
  content: string;
  createdAt: Date;
}

export class QueryPreprocessorService {
  async analyzeQuery(
    userQuery: string,
    chatHistory: ChatMessage[] = [],
    context?: string,
    additionalSearchDetail?: string
  ): Promise<QueryAnalysis> {
    try {
      console.log(`ðŸ§  PRE-FEED: Analyzing query "${userQuery}"`);

      let systemPrompt = `You are a query analysis AI for a knowledge management system. ${additionalSearchDetail ? `Additional Context: ${additionalSearchDetail}` : ''} Your job is to:

1. **CRITICAL: Inject Historical Context**
   - ALWAYS examine the chat history for relevant context, especially:
     - Recent image analysis mentions (look for system messages containing entity names, topics, or subjects)
     - Previous topic or entity discussions
     - Specific names, terms, or concepts mentioned in recent conversation
   - If the user's query is vague (e.g., "à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™", "à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ", "à¸¡à¸µà¸ªà¹ˆà¸§à¸™à¸¥à¸”à¸¡à¸±à¹‰à¸¢", "à¸—à¸³à¸¢à¸±à¸‡à¹„à¸‡", "à¸à¸µà¹ˆà¸§à¸±à¸™") but chat history contains specific context, YOU MUST inject that context into the enhanced query
   - Example: User says "à¸­à¸¢à¸¹à¹ˆà¸Šà¸±à¹‰à¸™à¹„à¸«à¸™" and history mentions "OPPO" â†’ Enhanced query should be "OPPO à¸­à¸¢à¸¹à¹ˆ à¸Šà¸±à¹‰à¸™"

2. Preprocess the user's query:
   - If the query is in Thai:
     - **PRIORITY** ALWAYS segment Thai text using PythaiNLP for proper word boundaries
     - Remove Thai stopwords such as: "à¸„à¸£à¸±à¸š", "à¸„à¹ˆà¸°", "à¹€à¸«à¸£à¸­", "à¹„à¸«à¸™", "à¸¢à¸±à¸‡à¹„à¸‡", "à¹„à¸«à¸¡", "à¸­à¹ˆà¸°", "à¸¥à¸°", etc.
     - Correct minor typos when possible (e.g., "à¸šà¸²à¸‡à¸à¸°à¸›à¸µ" â†’ "à¸šà¸²à¸‡à¸à¸°à¸›à¸´")
     - Mark as vague any query that is too short UNLESS you can inject historical context
     - For specific names, add English name to it when relevant. For example "à¹à¸¡à¸„ à¹‚à¸”à¸™à¸±à¸¥à¸”à¹Œ" add "McDonald's" to the prompt.
   - The returned query should be optimized for both keyword and semantic search. To optimize keyword search, ensure stopwords are removed and the query is segmented properly using PythaiNLP. For example,
     - Original: "à¸‹à¸·à¹‰à¸­à¸‚à¸­à¸‡ 6,000 à¹ƒà¸Šà¹‰à¸šà¸±à¸•à¸£à¹€à¸„à¸£à¸”à¸´à¸•à¹ƒà¸šà¹„à¸«à¸™à¸”à¸µ"
     - After segmentation: "à¸‹à¸·à¹‰à¸­ à¸‚à¸­à¸‡ 6,000 à¹ƒà¸Šà¹‰ à¸šà¸±à¸•à¸£à¹€à¸„à¸£à¸”à¸´à¸• à¹ƒà¸š à¹„à¸«à¸™ à¸”à¸µ"
     - Preferred: "à¸‹à¸·à¹‰à¸­ à¸‚à¸­à¸‡ 6,000 à¸šà¸±à¸•à¸£à¹€à¸„à¸£à¸”à¸´à¸•"
     - Not preferred: "à¸šà¸±à¸•à¸£à¹€à¸„à¸£à¸”à¸´à¸•à¹ƒà¸šà¹„à¸«à¸™à¸”à¸µ à¸ªà¸³à¸«à¸£à¸±à¸šà¸‹à¸·à¹‰à¸­à¸‚à¸­à¸‡ 6,000"
  - Increase the formality of the query because documents are typically written in formal language. For example, "à¸£à¹‰à¸²à¸™à¸«à¸¡à¸­à¸Ÿà¸±à¸™" should be "à¸„à¸¥à¸´à¸™à¸´à¸ à¸—à¸±à¸™à¸•à¸à¸£à¸£à¸¡"
  - **PRIORITY** If the query has English terms, keep it as is. For example, don't translate "Provident fund" to "à¸à¸­à¸‡à¸—à¸¸à¸™à¸ªà¸³à¸£à¸­à¸‡à¹€à¸¥à¸µà¹‰à¸¢à¸‡à¸Šà¸µà¸ž"

3. Determine if the user's query requires a document search:
   - Mark \`needsSearch: false\` if the query is vague, purely conversational, AND lacks historical context. For example, common short words like "à¹à¸", "à¸™à¸²à¸¢", "à¹€à¸˜à¸­", "à¸„à¸£à¸±à¸š", "à¸„à¹ˆà¸°", or openers like "à¸ªà¸§à¸±à¸ªà¸”à¸µ", "à¸§à¹ˆà¸²à¹„à¸‡", "à¸„à¸¸à¸“à¸Šà¸·à¹ˆà¸­à¸­à¸°à¹„à¸£", "à¸„à¸¸à¸“à¸—à¸³à¸­à¸°à¹„à¸£à¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡", or rhetorical/sarcastic lines like "à¹à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸ªà¸´à¸—à¸˜à¸´à¹Œà¸¡à¸²à¹€à¸£à¸µà¸¢à¸à¸‰à¸±à¸™à¸§à¹ˆà¸²à¸žà¹ˆà¸­"
   - Mark \`needsSearch: true\` if:
     â€¢ The query contains specific nouns or named entities (e.g., names, places, concepts, technical terms, policies, procedures)
     â€¢ The query follows an information-seeking pattern (e.g., "à¸¡à¸µà¹„à¸«à¸¡", "à¹€à¸›à¸´à¸”à¸à¸µà¹ˆà¹‚à¸¡à¸‡", "à¸•à¹‰à¸­à¸‡à¹ƒà¸Šà¹‰à¹€à¸­à¸à¸ªà¸²à¸£à¸­à¸°à¹„à¸£à¸šà¹‰à¸²à¸‡", "à¹„à¸”à¹‰à¸à¸µà¹ˆà¸§à¸±à¸™", "à¸—à¸³à¸¢à¸±à¸‡à¹„à¸‡", "à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™à¸„à¸·à¸­à¸­à¸°à¹„à¸£", "à¸§à¸´à¸˜à¸µà¸à¸²à¸£", "à¸à¸Žà¸£à¸°à¹€à¸šà¸µà¸¢à¸š")
     â€¢ The query can be made meaningful using recent chat history (e.g., pronouns like "à¸—à¸µà¹ˆà¸™à¸±à¹ˆà¸™", "à¸•à¸£à¸‡à¸™à¸±à¹‰à¸™", "à¸­à¸±à¸™à¸™à¸±à¹‰à¸™", "à¸¡à¸±à¸™", "à¸™à¸µà¹ˆ" after a previous topic)
     â€¢ The query asks about facts, processes, policies, or any information that might be documented
     â€¢ **CRITICAL** even though the information is already provided, the user might want to confirm the result or the results could be updated. Mark needSearch as true anyway!!!.

4. If a search is needed:
   - **PRIORITY 1**: Inject specific context from chat history (names, entities, topics, locations)
   - **PRIORITY 2**: Enhance with relevant terms and category context based on the domain:
     - For HR/policies: add relevant terms like "à¸™à¹‚à¸¢à¸šà¸²à¸¢", "à¸£à¸°à¹€à¸šà¸µà¸¢à¸š", "procedure"
     - For locations/services: add relevant location or service terms
     - For technical topics: add relevant technical terminology
   - Search anyway even though agent have answered in the history. The user might want to confirm the result.
     - For example, don't return false with this reason "Since the assistant has already provided a response indicating that information, the query does not require a new search", instead, return true because there might be an update in the data.

5. Set hybrid search weights:
   - Questions about **specific names, exact locations, contact details, or precise facts** â†’ High keyword weight (0.85â€“0.95)
   - **General recommendations, conceptual questions, or abstract needs** â†’ Higher semantic weight (0.8â€“0.9)
   - For example
     - "OPPO à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ à¸—à¹ˆà¸²à¸žà¸£à¸°" â†’ Keyword: 0.95, Semantic: 0.05"
     - "à¸§à¸´à¸˜à¸µ à¸à¸²à¸£ à¸¥à¸² à¸—à¸µà¹ˆ à¸”à¸µ à¸—à¸µà¹ˆà¸ªà¸¸à¸”" â†’ Keyword: 0.1, Semantic: 0.9"`;

      // Inject search configuration into system prompt if available
        if (additionalSearchDetail) {
          // Handle both direct search detail and context string formats
          let searchConfig = additionalSearchDetail;
          if (additionalSearchDetail.includes('Search Configuration:')) {
            const searchConfigMatch = additionalSearchDetail.match(/Search Configuration: (.+)/);
            if (searchConfigMatch) {
              searchConfig = searchConfigMatch[1];
            }
          }

          if (searchConfig && searchConfig.trim()) {
            systemPrompt += `

**SEARCH CONFIGURATION ENHANCEMENT:**
Additional search context: "${searchConfig}"
- CRITICAL: Incorporate this context when enhancing queries
- Use this to better understand the domain and purpose of the search
- Apply this context to make queries more specific and relevant
- When the user query is vague, use this context to provide better search terms`;
            console.log(`ðŸ§  PRE-FEED: Applied search configuration: "${searchConfig}"`);
          }
        }

      const chatHistoryText = chatHistory
        .slice(-5) // Last 5 messages for context
        .map(msg => `${msg.messageType}: ${msg.content}`)
        .join('\n');

      const userPrompt = `User Query: "${userQuery}"

Recent Chat History (EXAMINE CAREFULLY for context clues):
${chatHistoryText}

${context ? `Additional Context: ${context}` : ''}

**INSTRUCTIONS:**
1. Look for entity names, topics, or concepts mentioned in the chat history. Make sure you use correct terminology.
2. If the user query is vague but history contains specific context, inject that context
3. Pay special attention to image analysis results that mention specific entities or topics
4. Examples of context injection:
   - Query: "à¸­à¸¢à¸¹à¹ˆà¸Šà¸±à¹‰à¸™à¹„à¸«à¸™" + History mentions "OPPO", "à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ à¸—à¹ˆà¸²à¸žà¸£à¸°" â†’ Enhanced: "OPPO à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ à¸—à¹ˆà¸²à¸žà¸£à¸°"
   - Query: "à¸£à¸²à¸„à¸²à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ" + History mentions "iPhone 15" â†’ Enhanced: "iPhone 15 à¸£à¸²à¸„à¸²"

Analyze this query and provide your response.`;

      const response = await openai.chat.completions.create({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.1,
        max_tokens: 300
      });

      const content = response.choices[0]?.message?.content;
      if (!content) {
        throw new Error('No response from AI');
      }

      let analysis: QueryAnalysis;
      try {
        analysis = JSON.parse(content);
      } catch (parseError) {
        console.warn('Failed to parse AI response, using fallback analysis');
        analysis = this.getFallbackAnalysis(userQuery);
      }

      // Normalize weights to sum to 1
      const totalWeight = analysis.keywordWeight + analysis.vectorWeight;
      if (totalWeight > 0) {
        analysis.keywordWeight = analysis.keywordWeight / totalWeight;
        analysis.vectorWeight = analysis.vectorWeight / totalWeight;
      } else {
        analysis.keywordWeight = 0.5;
        analysis.vectorWeight = 0.5;
      }

      console.log(`ðŸ§  PRE-FEED RESULT:`, {
        needsSearch: analysis.needsSearch,
        original: userQuery,
        enhanced: analysis.enhancedQuery,
        weights: `K:${analysis.keywordWeight.toFixed(2)} V:${analysis.vectorWeight.toFixed(2)}`,
        reasoning: analysis.reasoning
      });

      return analysis;

    } catch (error) {
      console.error('Query preprocessing failed:', error);
      return this.getFallbackAnalysis(userQuery);
    }
  }

  private getFallbackAnalysis(userQuery: string): QueryAnalysis {
    // Simple fallback logic
    const lowerQuery = userQuery.toLowerCase();

    // Check if it's a location or factual question
    const isFactualQuery = /à¸­à¸¢à¸¹à¹ˆà¸—à¸µà¹ˆà¹„à¸«à¸™|à¸Šà¸±à¹‰à¸™à¹„à¸«à¸™|à¸—à¸µà¹ˆà¹„à¸«à¸™|where|location|floor|à¸£à¸²à¸„à¸²|à¹€à¸—à¹ˆà¸²à¹„à¸«à¸£à¹ˆ|à¸ªà¹ˆà¸§à¸™à¸¥à¸”|discount|à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™|process|à¸§à¸´à¸˜à¸µ|how|à¸­à¸°à¹„à¸£|what|à¹ƒà¸„à¸£|who|à¸—à¸³à¹„à¸¡|why|à¹€à¸¡à¸·à¹ˆà¸­à¹„à¸«à¸£à¹ˆ|when|à¸à¸µà¹ˆ|how many|à¸à¸µà¹ˆà¸§à¸±à¸™|how many days/.test(lowerQuery);

    // Check for specific entities or concepts (can be expanded)
    const hasSpecificEntity = /oppo|xolo|kfc|starbucks|uniqlo|provident fund|à¸à¸­à¸‡à¸—à¸¸à¸™à¸ªà¸³à¸£à¸­à¸‡à¹€à¸¥à¸µà¹‰à¸¢à¸‡à¸Šà¸µà¸ž|à¸¥à¸²à¸«à¸¢à¸¸à¸”|à¸ªà¸§à¸±à¸ªà¸”à¸´à¸à¸²à¸£|à¹€à¸šà¸´à¸à¹€à¸‡à¸´à¸™|à¸™à¹‚à¸¢à¸šà¸²à¸¢|à¸£à¸°à¹€à¸šà¸µà¸¢à¸š/.test(lowerQuery);

    // A query needs search if it's factual, has specific entities, or is not a short, purely conversational phrase.
    const needsSearch = isFactualQuery || hasSpecificEntity || lowerQuery.length > 5; // Heuristic for short, conversational phrases

    return {
      needsSearch,
      enhancedQuery: userQuery,
      keywordWeight: isFactualQuery || hasSpecificEntity ? 0.7 : 0.3,
      vectorWeight: isFactualQuery || hasSpecificEntity ? 0.3 : 0.7,
      reasoning: 'Fallback analysis due to AI preprocessing error or generic query detection'
    };
  }
}

export const queryPreprocessor = new QueryPreprocessorService();