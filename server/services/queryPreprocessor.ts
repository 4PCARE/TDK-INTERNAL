
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export interface QueryAnalysis {
  needsSearch: boolean;
  enhancedQuery: string;
  keywordWeight: number;
  vectorWeight: number;
  reasoning: string;
}

export interface ChatMessage {
  messageType: 'user' | 'assistant';
  content: string;
  createdAt: Date;
}

export class QueryPreprocessorService {
  async analyzeQuery(
    userQuery: string,
    chatHistory: ChatMessage[] = [],
    context?: string
  ): Promise<QueryAnalysis> {
    try {
      console.log(`ðŸ§  PRE-FEED: Analyzing query "${userQuery}"`);
      
      const systemPrompt = `You are a query analysis AI for a Thai shopping mall information system. Your job is to:

1. Preprocess the user's query:
   - If the query is in Thai:
     - Insert whitespace between Thai words if not already segmented
     - Remove Thai stopwords such as: "à¸„à¸£à¸±à¸š", "à¸„à¹ˆà¸°", "à¹€à¸«à¸£à¸­", "à¹„à¸«à¸™", "à¸¢à¸±à¸‡à¹„à¸‡", "à¹„à¸«à¸¡", "à¸­à¹ˆà¸°", "à¸¥à¸°", etc.
     - Correct minor typos when possible (e.g., "à¸šà¸²à¸‡à¸à¸°à¸›à¸µ" â†’ "à¸šà¸²à¸‡à¸à¸°à¸›à¸´")
     - Discard or mark as vague any query that is too short (e.g., single Thai words like "à¹à¸", "à¸¡à¸±à¸™", "à¸—à¸µà¹ˆ", "à¹€à¸‚à¸²", "à¹€à¸£à¸²") unless there is strong surrounding context

2. Determine if the user's query requires a document search:
   - Mark \`needsSearch: false\` if the query is vague, purely conversational, or lacks actionable terms
   - If the query includes a location, product, service, or store-related keyword, mark \`needsSearch: true\`

3. If a search is needed:
   - Enhance the query using relevant terms from chat history (e.g., specific store names, areas, etc.)
   - Nourish the query by appending inferred category or context terms such as:
     - For food or drink: \`"à¸­à¸²à¸«à¸²à¸£"\`, \`"à¸£à¹‰à¸²à¸™à¸­à¸²à¸«à¸²à¸£"\`, \`"dining"\`
     - For clothing or fashion: \`"à¹à¸Ÿà¸Šà¸±à¹ˆà¸™"\`, \`"à¹€à¸ªà¸·à¹‰à¸­à¸œà¹‰à¸²"\`, \`"fashion"\`
     - For banking, salons, services: \`"à¸šà¸£à¸´à¸à¸²à¸£"\`, \`"service"\`
   - Only append categories that help anchor the search to known document fields

4. Set hybrid search weights:
   - Questions about **store names, specific locations, contact details, or floor info** â†’ High keyword weight (0.7â€“0.8)
   - **General recommendations, service comparisons, or abstract needs** â†’ Higher semantic weight (0.6â€“0.8)

---

Respond in JSON format:
{
  "needsSearch": boolean,
  "enhancedQuery": "enhanced search phrase in Thai/English",
  "keywordWeight": 0.0-1.0,
  "vectorWeight": 0.0-1.0,
  "reasoning": "explanation of your decision"
}`;

      const chatHistoryText = chatHistory
        .slice(-5) // Last 5 messages for context
        .map(msg => `${msg.messageType}: ${msg.content}`)
        .join('\n');

      const userPrompt = `User Query: "${userQuery}"

Recent Chat History:
${chatHistoryText}

${context ? `Additional Context: ${context}` : ''}

Analyze this query and provide your response.`;

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3,
        max_tokens: 300
      });

      const content = response.choices[0]?.message?.content;
      if (!content) {
        throw new Error('No response from AI');
      }

      let analysis: QueryAnalysis;
      try {
        analysis = JSON.parse(content);
      } catch (parseError) {
        console.warn('Failed to parse AI response, using fallback analysis');
        analysis = this.getFallbackAnalysis(userQuery);
      }

      // Normalize weights to sum to 1
      const totalWeight = analysis.keywordWeight + analysis.vectorWeight;
      if (totalWeight > 0) {
        analysis.keywordWeight = analysis.keywordWeight / totalWeight;
        analysis.vectorWeight = analysis.vectorWeight / totalWeight;
      } else {
        analysis.keywordWeight = 0.5;
        analysis.vectorWeight = 0.5;
      }

      console.log(`ðŸ§  PRE-FEED RESULT:`, {
        needsSearch: analysis.needsSearch,
        original: userQuery,
        enhanced: analysis.enhancedQuery,
        weights: `K:${analysis.keywordWeight.toFixed(2)} V:${analysis.vectorWeight.toFixed(2)}`,
        reasoning: analysis.reasoning
      });

      return analysis;

    } catch (error) {
      console.error('Query preprocessing failed:', error);
      return this.getFallbackAnalysis(userQuery);
    }
  }

  private getFallbackAnalysis(userQuery: string): QueryAnalysis {
    // Simple fallback logic
    const lowerQuery = userQuery.toLowerCase();
    
    // Check if it's a location question
    const isLocationQuery = /à¸­à¸¢à¸¹à¹ˆà¹„à¸«à¸™|à¸Šà¸±à¹‰à¸™à¹„à¸«à¸™|à¸—à¸µà¹ˆà¹„à¸«à¸™|where|location|floor/.test(lowerQuery);
    
    // Check for store names
    const hasStoreName = /oppo|xolo|kfc|starbucks|uniqlo|à¸—à¸³à¹€à¸¥|à¸£à¹‰à¸²à¸™/.test(lowerQuery);
    
    const needsSearch = isLocationQuery || hasStoreName || lowerQuery.length > 3;
    
    return {
      needsSearch,
      enhancedQuery: userQuery,
      keywordWeight: isLocationQuery || hasStoreName ? 0.7 : 0.3,
      vectorWeight: isLocationQuery || hasStoreName ? 0.3 : 0.7,
      reasoning: 'Fallback analysis due to AI preprocessing error'
    };
  }
}

export const queryPreprocessor = new QueryPreprocessorService();
