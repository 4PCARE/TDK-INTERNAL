
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export interface QueryAnalysis {
  needsSearch: boolean;
  enhancedQuery: string;
  keywordWeight: number;
  vectorWeight: number;
  reasoning: string;
}

export interface ChatMessage {
  messageType: 'user' | 'assistant';
  content: string;
  createdAt: Date;
}

export class QueryPreprocessorService {
  private thaiStopwords = new Set([
    'à¸„à¸£à¸±à¸š', 'à¸„à¹ˆà¸°', 'à¹€à¸«à¸£à¸­', 'à¹„à¸«à¸™', 'à¸™à¸°', 'à¸«à¸£à¸·à¸­', 'à¹€à¸­à¹‡à¸‡', 'à¸à¸¹', 'à¸¡à¸±à¸‡', 'à¸§à¸°', 
    'à¸«à¸§à¹ˆà¸²', 'à¹€à¸®à¹‰à¸¢', 'à¹€à¸­à¸²', 'à¹„à¸”à¹‰', 'à¹à¸¥à¹‰à¸§', 'à¸ˆà¸°', 'à¹„à¸›', 'à¸¡à¸²', 'à¸­à¸¢à¸¹à¹ˆ', 'à¹€à¸›à¹‡à¸™',
    'à¸—à¸µà¹ˆ', 'à¹ƒà¸™', 'à¸à¸±à¸š', 'à¹à¸¥à¸°', 'à¸«à¸£à¸·à¸­', 'à¹à¸•à¹ˆ', 'à¹€à¸žà¸£à¸²à¸°', 'à¸–à¹‰à¸²', 'à¹€à¸¡à¸·à¹ˆà¸­'
  ]);

  private commonTypos = new Map([
    ['à¸­à¸›à¸›à¹Œ', 'OPPO'],
    ['à¹‚à¸­à¸›à¹‚à¸›', 'OPPO'],
    ['à¹‚à¸­à¸›à¸›à¹Œ', 'OPPO'],
    ['à¸‡à¸²à¸¡à¸§à¸‡à¸§à¸²à¸™', 'à¸‡à¸²à¸¡à¸§à¸‡à¸¨à¹Œà¸§à¸²à¸™'],
    ['à¸‡à¸²à¸¡à¸§à¸­à¸‡à¸§à¸²à¸™', 'à¸‡à¸²à¸¡à¸§à¸‡à¸¨à¹Œà¸§à¸²à¸™'],
    ['à¸šà¸²à¸‡à¸à¸°à¸›à¸´', 'à¸šà¸²à¸‡à¸à¸°à¸›à¸´'], // Already correct but common
    ['à¸šà¸²à¸‡à¹à¸', 'à¸šà¸²à¸‡à¹à¸„'],
    ['à¸—à¸²à¸žà¸£à¸°', 'à¸—à¹ˆà¸²à¸žà¸£à¸°'],
    ['à¸—à¹ˆà¸²à¸žà¸£à¸²', 'à¸—à¹ˆà¸²à¸žà¸£à¸°'],
    ['à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥', 'à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ'],
    ['à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ', 'à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œ'], // Already correct
    ['à¹„à¸¥à¸Ÿà¸ªà¹‚à¸•à¸£à¹Œ', 'à¹„à¸¥à¸Ÿà¹Œà¸ªà¹‚à¸•à¸£à¹Œ'],
    ['à¹„à¸¥à¸Ÿà¹Œà¸ªà¸•à¸­à¸£à¹Œ', 'à¹„à¸¥à¸Ÿà¹Œà¸ªà¹‚à¸•à¸£à¹Œ']
  ]);

  private preprocessThaiText(text: string): string {
    console.log(`ðŸ§  PRE-PROCESSING: Original text "${text}"`);
    
    // Step 1: Basic whitespace normalization
    let processed = text.trim().replace(/\s+/g, ' ');
    
    // Step 2: Add whitespace between Thai and English words
    processed = processed.replace(/([à¸-à¹™])([A-Za-z])/g, '$1 $2');
    processed = processed.replace(/([A-Za-z])([à¸-à¹™])/g, '$1 $2');
    
    // Step 3: Add whitespace between Thai words (basic segmentation)
    // This is a simple approach - for better results, you'd use a proper Thai word segmentation library
    processed = processed.replace(/([à¸-à¹™]{2,})([à¸-à¹™]{2,})/g, (match, p1, p2) => {
      // Simple heuristic: if we have compound words, try to separate them
      if (match.length > 6) {
        const mid = Math.floor(match.length / 2);
        return match.slice(0, mid) + ' ' + match.slice(mid);
      }
      return match;
    });
    
    // Step 4: Correct common typos
    this.commonTypos.forEach((correct, typo) => {
      const regex = new RegExp(typo, 'gi');
      processed = processed.replace(regex, correct);
    });
    
    // Step 5: Remove stopwords
    const words = processed.split(/\s+/);
    const filteredWords = words.filter(word => {
      const cleanWord = word.toLowerCase().trim();
      return cleanWord.length > 0 && !this.thaiStopwords.has(cleanWord);
    });
    
    processed = filteredWords.join(' ');
    
    console.log(`ðŸ§  PRE-PROCESSING: Processed text "${processed}"`);
    return processed;
  }

  async analyzeQuery(
    userQuery: string,
    chatHistory: ChatMessage[] = [],
    context?: string
  ): Promise<QueryAnalysis> {
    try {
      console.log(`ðŸ§  PRE-FEED: Analyzing query "${userQuery}"`);
      
      // Preprocess Thai text
      const preprocessedQuery = this.preprocessThaiText(userQuery);
      console.log(`ðŸ§  PRE-FEED: Preprocessed query "${preprocessedQuery}"`);
      
      const systemPrompt = `You are a query analysis AI for a Thai shopping mall information system. Your job is to:

1. Determine if the user's question requires a document search
2. If yes, enhance the search query with context from chat history
3. Set optimal hybrid search weights (keyword vs semantic)

Guidelines:
- Questions about specific store locations, floor numbers, or contact details â†’ High keyword weight (0.7-0.8)
- General questions about services, recommendations, or explanations â†’ High semantic weight (0.6-0.8)
- Questions asking "where is this store" when mentioned earlier â†’ Include store name in enhanced query
- Questions in Thai about locations often use "à¸­à¸¢à¸¹à¹ˆà¹„à¸«à¸™", "à¸Šà¸±à¹‰à¸™à¹„à¸«à¸™", "à¸—à¸µà¹ˆà¹„à¸«à¸™"
- Store names like OPPO, XOLO, etc. should be preserved exactly
- Mall names like "à¹€à¸”à¸­à¸°à¸¡à¸­à¸¥à¸¥à¹Œà¸‡à¸²à¸¡à¸§à¸‡à¸¨à¹Œà¸§à¸²à¸™", "à¸šà¸²à¸‡à¸à¸°à¸›à¸´" should be included when relevant

Respond in JSON format:
{
  "needsSearch": boolean,
  "enhancedQuery": "improved search phrase in Thai/English",
  "keywordWeight": 0.0-1.0,
  "vectorWeight": 0.0-1.0,
  "reasoning": "explanation of your decision"
}`;

      const chatHistoryText = chatHistory
        .slice(-5) // Last 5 messages for context
        .map(msg => `${msg.messageType}: ${msg.content}`)
        .join('\n');

      const userPrompt = `Original User Query: "${userQuery}"
Preprocessed Query: "${preprocessedQuery}"

Recent Chat History:
${chatHistoryText}

${context ? `Additional Context: ${context}` : ''}

Use the preprocessed query for analysis, but consider both versions for context. Analyze this query and provide your response.`;

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.3,
        max_tokens: 300
      });

      const content = response.choices[0]?.message?.content;
      if (!content) {
        throw new Error('No response from AI');
      }

      let analysis: QueryAnalysis;
      try {
        analysis = JSON.parse(content);
      } catch (parseError) {
        console.warn('Failed to parse AI response, using fallback analysis');
        analysis = this.getFallbackAnalysis(userQuery);
      }

      // Normalize weights to sum to 1
      const totalWeight = analysis.keywordWeight + analysis.vectorWeight;
      if (totalWeight > 0) {
        analysis.keywordWeight = analysis.keywordWeight / totalWeight;
        analysis.vectorWeight = analysis.vectorWeight / totalWeight;
      } else {
        analysis.keywordWeight = 0.5;
        analysis.vectorWeight = 0.5;
      }

      // If AI didn't enhance the query much, use our preprocessed version
      if (analysis.enhancedQuery === userQuery || analysis.enhancedQuery.length < preprocessedQuery.length) {
        analysis.enhancedQuery = preprocessedQuery;
      }

      console.log(`ðŸ§  PRE-FEED RESULT:`, {
        needsSearch: analysis.needsSearch,
        original: userQuery,
        preprocessed: preprocessedQuery,
        enhanced: analysis.enhancedQuery,
        weights: `K:${analysis.keywordWeight.toFixed(2)} V:${analysis.vectorWeight.toFixed(2)}`,
        reasoning: analysis.reasoning
      });

      return analysis;

    } catch (error) {
      console.error('Query preprocessing failed:', error);
      return this.getFallbackAnalysis(userQuery);
    }
  }

  private getFallbackAnalysis(userQuery: string): QueryAnalysis {
    // Use preprocessed text for fallback analysis
    const preprocessedQuery = this.preprocessThaiText(userQuery);
    const lowerQuery = preprocessedQuery.toLowerCase();
    
    // Check if it's a location question
    const isLocationQuery = /à¸­à¸¢à¸¹à¹ˆ|à¸Šà¸±à¹‰à¸™|à¸—à¸µà¹ˆ|where|location|floor/.test(lowerQuery);
    
    // Check for store names
    const hasStoreName = /oppo|xolo|kfc|starbucks|uniqlo|à¸—à¸³à¹€à¸¥|à¸£à¹‰à¸²à¸™/.test(lowerQuery);
    
    const needsSearch = isLocationQuery || hasStoreName || lowerQuery.length > 3;
    
    return {
      needsSearch,
      enhancedQuery: preprocessedQuery,
      keywordWeight: isLocationQuery || hasStoreName ? 0.7 : 0.3,
      vectorWeight: isLocationQuery || hasStoreName ? 0.3 : 0.7,
      reasoning: 'Fallback analysis with Thai text preprocessing'
    };
  }
}

export const queryPreprocessor = new QueryPreprocessorService();
