Now you're talking real **statistical firepower ğŸ”¥**.

You're absolutely on the right path â€” calculating **TF-IDF per chunk**, then applying **normalization or standardization** across the full batch, is a **much more principled** and **robust** way to balance your hybrid scores.

Letâ€™s walk through how and *why* it works â€” and how you can plug it into your current pipeline.

---

### ğŸ” Step-by-step: How to Improve Your TF-IDF Scoring

#### âœ… Step 1: **Calculate raw TF-IDF per chunk**

You're already doing this:

```ts
const tfidfScore = ...; // per chunk
```

Perfect. Don't stop there.

---

#### âœ… Step 2: **Collect all scores into an array**

Before scoring final ranks, gather all TF-IDF values:

```ts
const allTfidfScores = Array.from(tfidfResults.values()).map(res => res.score);
```

---

#### ğŸ¯ Option 1: **Min-max normalization**

Scale scores to \[0, 1] range:

```ts
const minScore = Math.min(...allTfidfScores);
const maxScore = Math.max(...allTfidfScores);

const normalized = (score - minScore) / (maxScore - minScore + 1e-8); // +epsilon to avoid /0
```

ğŸ”¹ **Pros**: Keeps relative order, perfect for score fusion
ğŸ”¹ **Cons**: Sensitive to outliers (like one big TF-IDF spike)

---

#### ğŸ§  Option 2: **Z-score standardization**

Transform scores into standard deviations from the mean:

```ts
const mean = allTfidfScores.reduce((a, b) => a + b, 0) / allTfidfScores.length;
const std = Math.sqrt(allTfidfScores.reduce((sum, s) => sum + (s - mean) ** 2, 0) / allTfidfScores.length);

const standardized = (score - mean) / (std + 1e-8);
```

Then you can squish that into \[0,1] using a sigmoid:

```ts
const sigmoid = (x) => 1 / (1 + Math.exp(-x));
const bounded = sigmoid(standardized); // gives smooth [0,1]
```

ğŸ”¹ **Pros**: Handles uneven score distributions
ğŸ”¹ **Cons**: Might "flatten" high scores if data is very skewed

---

### ğŸ”„ Why it's Better than `/2`

| Metric           | `/2` Method | Min-Max / Z-Score             |
| ---------------- | ----------- | ----------------------------- |
| Adaptiveness     | âŒ Fixed     | âœ… Dynamic                     |
| Accuracy         | ğŸ¯ Rough    | ğŸ¯ Much better                |
| Code effort      | âœ… Easy      | âš ï¸ Slightly more, but not bad |
| Interpretability | âœ… Obvious   | âš ï¸ Need to explain to humans  |

---

### ğŸ§ª Pro Tip

If you go with **Z-score**, try setting a cutoff:

```ts
if (standardized < -1.5) skip; // very irrelevant
```

Or even just clip it:

```ts
const clipped = Math.max(-3, Math.min(3, standardized));
```

---

### ğŸ”š TL;DR

> âœ… **Yes, calculating per-chunk TF-IDF, then normalizing across the batch, is way better**
> It makes your keyword score **comparable** to vector scores
> It gives **real weight to meaningful hits** without hardcoding `/2`

---

Wanna test it right now on your TF-IDF batch? I can help rewrite that scoring function live.
